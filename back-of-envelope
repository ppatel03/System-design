Links :

https://bytebytego.com/courses/system-design-interview/back-of-the-envelope-estimation

https://matthewdbill.medium.com/back-of-envelope-calculations-cheat-sheet-d6758d276b05

Tips :
- Ask functional requirements first (example, ability to post tweet, view tweet)
- Ask DAU. If MAU is provided, atleast ask % of daily users. 
- Ask user activity : example read vs write ratio, or number of writes (example, 2 tweets per day)
- Ask non-functional requirements 
  These are very important and can convert entire inteview in your favor. Example if latency is 1s, then you do not need complex caching architecture.
    -- Latency 
           this would help decide whether you really need low latency optimizations like cache, or not. 
           Remember today mosts have 1 Gbps network which has 10 us to transfer 1 KB
    -- Availability 
          this would help decide the redundancy and reliability - example mostly 99.99% a day means you can compromise 10s (10 ^ 5 * 10 ^ -4)
          of unavailability or being unrelible. With this you can even decide that, your system could be out of sync from third part servers for 10s in a
          day

QPS estimate
- 1 day ~ 10^5 s
- 1 month ~ 3 * 10 ^ 6s and further ~ 10 ^ 6s
- 1 week ~ 7 * 10 ^ 5s and further ~ 10 ^ 6s
----- For time constraints, do not hesitate to round off large amounts

Distributed Systems estimate

Estimates in KB

Send 1 KB sequential from 1 Gbps network = 10 us  
Send 1 KB sequential from memory  = 0.25 us   (4 GB/s = 0.25 *  10 ^ -6 s) 
Send 1 KB sequential from disk    = 30 us     (30 MB/s = 0.03 * 10 ^ -3 s ) 
Send 1 KB sequential from cache   = 1 us    (1 GB/s = 1 * 10 ^ -6 s ) 

So network is 3 times faster than disk
memory is 40 times faster than network

Benchmarks on common systems

Cache
Azure Redis Cache : 
  53 GB, with 99.9% availability (https://github.com/Huachao/azure-content/blob/master/articles/redis-cache/cache-faq.md)
  230 us (https://redis.io/docs/management/optimization/latency/)




================================================================
================================================================
================================================================

References

Dump : https://coursehunters.online/t/educative-io-design-gurus-grokking-the-system-design-interview-part-5/584
Quick read : https://github.com/Jeevan-kumar-Raj/Grokking-System-Design


================================================================

- Key characteristics
    Resources
      https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/key-characteristics.md 
    Scalability, Availability, Reliability, Efficiency and Servicability/Manageability
    -> Remember an Avaiability system does not means Reliable but Reliable system is always available. 
    
================================================================

    
- Load balancing
    Resources
      https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/load-balancing.md
      https://www.cloudflare.com/learning/performance/types-of-load-balancing-algorithms/
      https://igotanoffer.com/blogs/tech/load-balancing-system-design-interview
    Static load balancing - round robin, weight round robin, IP hash
    Dynamic load balanacing - least connection, least resource, least response time, least bandwidht
    When to use Static ?
      If the server pool and the requests are both homogeneous, and there is only one balancer
    When to use Dynamic ?
      if the requests are heterogenous, Least Load is helpful to prevent servers from being intermittently overloaded.
      
    What are Hardware load balancers ?
      They have high performant hardware resources like L4 and L7. 
      Read about L4 and L7 here https://levelup.gitconnected.com/l4-vs-l7-load-balancing-d2012e271f56
      
    What are Software load balancers ?
      They run on standard servers and are less hardware optimized, but cheaper to set up and run. Example, Nginx or HAProxy. For Nginx 100s video, 
      refer https://www.youtube.com/watch?v=JKxlsvZXG7c. Nginx can serve routing to different servers, rate limiting, handle spikes,
      reverse proxy, security, cache, etc. 
      
    When to use Software or Hardware ?
      Tip : Since software load balancing can run on ordinary hardware and supports, always prefer software load balancer. Example Nginx
       
      
    What is proxy server, reverse proxy and API Gateway ? How is different from load balancer
      proxy vs reverse proxy vs load balancer : https://www.youtube.com/watch?v=MiqrArNSxSM
      Proxy : just protects the client side
      Reverse Proxy : protects the server by serving as proxy for all backend services - routing, rate limitng, load balancing
      API gateway : rate limiting, routing, handle spikes
      Load balancer : only performs load balancing
      
      So Reverse proxy can perform both API Gateway and Load Balancing. Example nginx.
      A load balancer can never be API gateway or reverse proxy.
      
     Always choose Nginx ? Why ?
       Has triats of load balancing + reverse proxy + API gateway
         - supports load balancing
         - supports reverse proxy 
         - supports rate limiting
         - supports caching
         - supports request grouping
         - supports secure auth
       Nginx supports L7
================================================================

      
  - Caching
    Resources
      https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/caching.md
      Distributed cache on Application server VS Global cache like Redis, (mostly preferred)
      CDN is another form of cache for static content but its often expensive
      
          
       What are different caching strategies ? 
          https://codeahoy.com/2017/08/11/caching-strategies-and-how-to-choose-the-right-one/
          Cache-Aside (application server has cache aside like Redis, Memcache and DB separately)
            - Pros : logic controlled by application server, resilent to cache failures, data model in cache vs db could be different
            - Cons : stale data in cache for db writes
          Read-Through Cache (application server reads from cache only)
            - Pros : logic controlled by cache, read-heavy, good consistency when combined with write through 
            - Cons : needs data model to be consistent, first time data always results in cache miss

          Belpw are Cache writes invalidation policy 

          Write through (data is written to cache and synced with storage)
            - Pros : fast retreival and data consistent systems
            - Cons : slow writes though
          Write around (data is written to storage, not cache)
            - Pros : Saves write operation on the cache
            - Cons : recently written data creates a cache miss and higher latency.
          Write back (data is written to cache only, then synced later to storage)
            - Pros : fast retreival, low latency read / writes
            - Cons : Risk of data loss
            
        Real applications of 
          1. read-through, write-through for high consistency
                DynamoDB Accelerator (DAX) for dynamoDB
          2. read-through, write-around for high performance for situations where data is written once and read less frequently or never.
                real-time logs, chatroom messages
          3. cache-aside, write back cache to absorb spikes during peak load
                custom applications using redis
          4. write back cache
                InnoDB which is relational database storage engine. Queries are first written to memory and eventually flushed to the disk.
                
                
================================================================
    - Sharding / Partitioning 
        Resources
          https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/sharding.md
          https://coursehunters.online/t/educative-io-design-gurus-grokking-the-system-design-interview-part-5/584
          Horizontal, Vertical and Directory based paritioning
            Directory based paritioning has work around to solve some challenges with Horizontal and Vertical?
          What's the best Partitioning criteria ?
            Consitent hashing which is combination of hash and list based partitioning
          Commom problems with Sharding / Partitioning
            Joins -> Denormalization
            Referential Integrity
            Hot shard problem needs rebalancing
              How to rebalance ? 
              It would take downtime, check directory based partitioning as per our educative.io resource.
              But consistent hashing can solve this problem better - https://medium.com/nerd-for-tech/consistent-hashing-6524e48ac648
              Great guide above - check consistent hashing with gossip protocol so that each partition knows where to fetch data from db
          Applications of consistent hashing ?
          Apache Cassandra, Dynamo DB
 
 ================================================================

    - Indexing
        Resources
          https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/indexes.md
          What is a database index ? 
            https://www.codecademy.com/article/sql-indexes
          Pros
            helps in speeding up the search 
          Cons
            lowers write/update/delete performance
          When to use indexes ?
            In the case of data sets that are many terabytes in size but with very small payloads (e.g., 1 KB), 
            indexes are a necessity for optimizing data access. Finding a small payload in such a large dataset can be a real challenge since
            we can’t possibly iterate over that much data in any reasonable time. Furthermore, it is very likely that such a large data set is 
            spread over several physical devices—this means we need some way to find the correct physical location of the desired data. 
            Indexes are the best way to do this.
            
   ================================================================

     - Proxy 
        Resources
          https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/proxies.md
          
          Usage : 
          filter requests, log requests, cache, encryption and most important batch request. Further, it can get smarter to o collapse requests 
          for data that is spatially close together in the storage (consecutively on disk). This strategy will result in decreasing request latency. 
          For example, let’s say a bunch of servers request parts of file: part1, part2, part3, etc. We can set up our proxy in such a way 
          that it can recognize the spatial locality of the individual requests, thus collapsing them into a single request and reading complete file, 
          which will greatly minimize the reads from the data origin.
          
          Proxy are of two types 
          Client proxy to protect the clients
          Server proxy to protect the servers. Also called reverse proxy
          
          Should we use proxy then?
          Only use proxy to protect the client.
          For server side, Always Nginx since its open source and supports both reverse proxy + load balancing + API gateway.
          
          
   
      ================================================================

          
          
        
        
  
  

      
      



