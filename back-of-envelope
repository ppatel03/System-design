Links :

https://bytebytego.com/courses/system-design-interview/back-of-the-envelope-estimation

https://matthewdbill.medium.com/back-of-envelope-calculations-cheat-sheet-d6758d276b05

Tips :
- Ask functional requirements first (example, ability to post tweet, view tweet)
- Ask DAU. If MAU is provided, atleast ask % of concurrent users. 
- Ask user activity : example read vs write ratio, or number of writes (example, 2 tweets per day)
- Ask non-functional requirements 
  These are very important and can convert entire inteview in your favor. Example if latency is 1s, then you do not need complex caching architecture if your data transfer is less than 100 MB (100 MBps max bandwidth today)
    -- Latency 
           this would help decide whether you really need low latency optimizations like cache, or not. 
           Remember today mosts have 1 Gbps network which has 10 us to transfer 1 KB
    -- Availability 
          this would help decide the redundancy and reliability - example mostly 99.99% a day means you can compromise 10s (10 ^ 5 * 10 ^ -4)
          of unavailability or being unrelible. With this you can even decide that, your system could be out of sync from third part servers for 10s in a day but that's reliability or consistency measurement though
    


QPS estimate
- Read : Write ratio
  DO NOT divided by no. of seconds to get QPS if its explictly mentioned about concurrent users say 10% of DAU. In such cases, QPS = 10% DAU
- 1 day ~ 10^5 s
- 1 month ~ 3 * 10 ^ 6s and further ~ 10 ^ 6s
- 1 week ~ 7 * 10 ^ 5s and further ~ 10 ^ 6s
----- For time constraints, do not hesitate to round off large amounts

How to use non-functional requirements in decison making

  Availability vs Reliablity 
    https://www.pagerduty.com/resources/learn/reliability/ 
    Availability is a measure of the percentage of time that an IT service or component is in an operable state.
    Reliability, on the other hand, is a measure of the probability that the system will meet defined performance standards in performing its intended function during a specified interval.  

  Bandwidth (assume to be 1 GBps ~ 100 MBps which means 1 KB = 10us) 
    - can help reason your latency
    - can help reason your replication or multiple servers
    - can help reason your sharding for database (remember internal data center max bandwidth to 25 Gbps ~ 2.5 GBps which means 1 KB = 1us ) https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-network-bandwidth.html 

  Durability  (I even refer as availability + data correctness with techniques like checksum, parity)
    - can help reason how much to replicate. 
        Example, say 99.999999% (six 9's) durability can be achieved assuming failure rate of one server is 0.01% (say 99.99% guarantee for ec2 on aws). This means you need 2 servers atleast which means 1 replica (0.0001 ^ 2 = 0.0000001. So 1 - 0.0000001 ~ 0.99999999 * 100 ~ 99.999999% ) 
    - can help to reason out if you need checksum for data integrity

  Availability
    - can help reason how much to replicate. See above
    - can help reason for latency 

  Consistency
    - can help reason for high latency 
    - can help reason for low replication
    - can help reason for MySQL if combined with ACID


Back of envelope questions : 
  1. calculate qps (round this number).  
      Why ? 
        - help in estimating bandwidth and reasons out the need for distributed system
        - helps in estimating storage requirements
  2. if latency requirement is present, calculate api payload rough estimate say 1 KB for 100K QPS ~ 100 MBps
      Why ? 
        - helps in estimating # of servers needed 
  3. calculate storage estimate 
      Why ? 
     - to help decide if sharding is need or master-replica model. Example 100 PB of storage needs sharding





Distributed Systems estimate

    Latency video
      https://www.youtube.com/watch?v=FqR5vESuKe0
      https://bytebytego.com/courses/system-design-interview/back-of-the-envelope-estimation
      https://matthewdbill.medium.com/back-of-envelope-calculations-cheat-sheet-d6758d276b05 

    Estimates in KB

    Send 1 KB sequential from 1 Gbps network = 10 us  
    Send 1 KB sequential from memory  = 0.25 us   (4 GB/s = 0.25 *  10 ^ -6 s) 
    Send 1 KB sequential from disk    = 30 us     (30 MB/s = 0.03 * 10 ^ -3 s ) 
    Send 1 KB sequential from SSD   = 1 us    (1 GB/s = 1 * 10 ^ -6 s )

    L1/L2 cache = 1 ns
    L3 shared cache = 10 ns
    Memory call = 100 ns
    System call = 1 us
    Context switching between linux threads : 10 us
    Ngnix to process http request : 100 us
    SSD write latency : 500 us
    Round trip within the same datacenter	 = 500 us 
    Redis cache latency including network : 1 ms (usually 500 us by internal redis)
    Send packet CA (California) ->Netherlands->CA	= 150 ms 
    Mutex lock/unlock =	100 ns
    Disk seek	= 10 ms
    SSD latency = 16 us
    DNS response time ranges : 10ms to 200ms.
    Multi-region failover time for AWS RDS : 60-100s  https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZSingleStandby.html
    Replication lag for AWS RDS : < 100 ms 
      https://www.bluematador.com/docs/troubleshooting/rds-replica-lag#:~:text=Replication%20lag%20measures%20how%20far,than%20100ms%20of%20replication%20lag. 
    TLS handshake time : 250 - 500 ms https://zoompf.com/blog/2014/12/optimizing-tls-handshake/#:~:text=This%20handshake%20will%20typically%20take,is%20when%20the%20handshake%20happens. 
      So suggest to use nginx for keep alive and caching session key 
    Max connections on the server : 
        https://josephmate.github.io/2022-04-14-max-connections
        Some think the limit 216=65,536 because that’s all the ports available in the TCP spec.
        Then theoretical limit a server can support on a single port is 2^48 which is about 1 quadrillion. This is huge and not possible.
        So basically, your # of connections depends on CPU, Mem, Network and other resources on the server.
        So to estimate max connections, use request size to memory mapping. Example, At 1M concurrent users, assuming each user connection needs 10K of memory on the server (this is a very rough figure and very dependent on the language choice - 256 KB for hava), it only needs about 10GB of memory to hold all the connections on one box.


    Modern fiber optic cable vs ethernet (copper) cable
      - 10 Gbps vs 1 Gbps
      - https://www.cablewholesale.com/blog/index.php/2020/09/16/fiber-optic-vs-copper-ethernet-cables-the-difference/#:~:text=A%20more%20modern%20take%20on,much%20faster%20than%20copper%20cables.


=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================


Distributed best practices

  Smallest short length required ( say for tiny url )
    The hashValue consists of characters from [0-9, a-z, A-Z], containing 10 + 26 + 26 = 62 possible characters. To figure out the length of hashValue, find the smallest n such that 62^n ≥ 365 billion. 

  Choices with protocol
    - TCP vs UDP
        https://www.spiceworks.com/tech/networking/articles/tcp-vs-udp/#:~:text=UDP%20is%20faster%20and%20more,connection%20to%20start%20sending%20packets.
        1. TCP is connection-oriented while UDP is connectionless
        The UDP protocol is not suitable for sending electronic mail, viewing a web page, or downloading a file. However, it is preferred mainly for real-time applications like broadcasting or multitasking network traffic.

  Failure detection algo 
    - gossip prototocol to detect availability failures in distributed systems
    - Raft (description below) using used for master-replica model
      Ensure all replicas are always in-sync and master->slave is elected correctly when master goes down. We could use consensus algorithms such as Paxos [21] and Raft [22], or use consensus-based distributed databases such as YugabyteDB [23] or CockroachDB [24].
          https://bytebytego.com/courses/system-design-interview/stock-exchange 
          The leader sends heartbeat messages (AppendEnties with no content as shown in Figure 21) to its followers. If a follower has not received heartbeat messages for a period of time, it triggers an election timeout that initiates a new election. The first follower that reaches election timeout becomes a candidate, and it asks the rest of the followers to vote (RequestVote). If the first follower receives a majority of votes, it becomes the new leader.


  Failure handling algo
  - for temporary failures
      1. Sloppy quorum
        
  - for permenant failures          
      1. Merklee tree (can detect and handle failures by syncing remaining replicas)
          What if a replica is permanently unavailable? To handle such a situation, we implement an anti-entropy protocol to keep replicas in sync. Anti-entropy involves comparing each piece of data on replicas and updating each replica to the newest version. A Merkle tree is used for inconsistency detection and minimizing the amount of data transferred.
          Quoted from Wikipedia [7]: “A hash tree or Merkle tree is a tree in which every non-leaf node is labeled with the hash of the labels or values (in case of leaves) of its child nodes. Hash trees allow efficient and secure verification of the contents of large data structures”.
                Step 1: Divide key space into buckets (4 in our example) as shown in Figure 13. A bucket is used as the root level node to maintain a limited depth of the tree.
                Step 2: Once the buckets are created, hash each key in a bucket using a uniform hashing method (Figure 14).
                Step 3: Create a single hash node per bucket (Figure 15).
                Step 4: Build the tree upwards till root by calculating hashes of children (Figure 16).
          https://bytebytego.com/courses/system-design-interview/design-a-key-value-store

  Directed acyclic graph (DAG) model
        To support different video processing pipelines and maintain high parallelism, it is important to add some level of abstraction and let client programmers define what tasks to execute. For example, Facebook’s streaming video engine uses a directed acyclic graph (DAG) programming model, which defines tasks in stages so they can be executed sequentially or parallelly [8]. In our design, we adopt a similar DAG model to achieve flexibility and parallelism. Figure 8 represents a DAG for video transcoding.

  Symmetric vs Asymmetric encryption
    https://blog.mailfence.com/symmetric-vs-asymmetric-encryption/ 
    RSA is asymmetric
    Rest everything is symmetric
    SHA-1 is hash function and not encryption one

  Eliminate disk access
    Disk accesses can be eliminated using mmap. `mmap(2)` provides a mechanism for high-performance sharing of memory between processes. Modern exchanges take advantage of this to eliminate as much disk access from the critical path as possible. `mmap(2)` is used in the server to implement a message bus over which the components on the critical path communicate. The communication pathway has no network or disk access, and sending a message on this mmap message bus takes sub-microsecond. By leveraging mmap to build an event store, coupled with the event sourcing design paradigm which we will discuss next, modern exchanges can build low-latency microservices inside a server.

  Change Data Capture
  CDC is a mechanism that reads data changes from the database and applies the changes to another data system. One common solution is Debezium [9]. It uses a source connector to read changes from a database and applies them to cache solutions such as Redis [10].

  In-sync replicas
    https://bytebytego.com/courses/system-design-interview/distributed-message-queue
    We mentioned that messages are persisted in multiple partitions to avoid single node failure, and each partition has multiple replicas. Messages are only written to the leader, and followers synchronize data from the leader. One problem we need to solve is keeping them in sync.
    In-sync replicas (ISR) refer to replicas that are “in-sync” with the leader. The definition of “in-sync” depends on the topic configuration. For example, if the value of replica.lag.max.messages is 4, it means that as long as the follower is behind the leader by no more than 3 messages, it will not be removed from ISR [10]. The leader is an ISR by default.

  Data mirroring with replicas
    https://bytebytego.com/courses/system-design-interview/distributed-message-queue 
    If all the replicas of a partition crash, the data for that partition is lost forever. When choosing the number of replicas and replica locations, there’s a trade-off between data safety, resource cost, and latency. It is safer to distribute replicas across data centers, but this will incur much more latency and cost, to synchronize data between replicas. As a workaround, data mirroring can help to copy data across data centers, but this is out of scope. The reference material [14] covers this topic.

  Authentication and Security 
        Asymmetric encryption could be used here for payment gateway
          https://www.youtube.com/watch?v=AQDCe585Lnc
          also used in HTTPS, SSH, Bitcoin, Emails using PGP protocol

        How HTTPS works ? How it uses SSL and TLS
          https://www.youtube.com/watch?v=hExRDVZHhig
          HTTPS uses public key encryption to secure data using SSL (Secure socket layer) protocol. Basically server gives SSL certicate to client and acknowledgement is established between the two. Then info can be transferred securely using encryption.
          TLS is latest and successor of SSL
          Today most websites supports https because of google standards

          ByteByteGo : https://www.youtube.com/watch?v=j9QmMEWmcfo
            Moderm HTTPS uses TLS
            1. first establishes TCP handshake at transport 
            2. then client sends hello and gets the certificate from server which has public key of server (Asymmetric) 
            3. then client encryptes his/her session key with server's public key and then on server, it gets clients sesssion key by decrypting with server's private key. This is Asymmetric encryption
            4. Now both has session key and uses session key as cipher to encrypt and decrypt at both sides. This is Symmetric encryption.

            SSL uses public key encryption (Asymmetric encryption) only. However, this website claims it supports both Asymmetric and symmetric - https://www.trentonsystems.com/blog/symmetric-vs-asymmetric-encryption
          

        TLS handshake latency 
          TLS handshake time : 250 - 500 ms https://zoompf.com/blog/2014/12/optimizing-tls-handshake/#:~:text=This%20handshake%20will%20typically%20take,is%20when%20the%20handshake%20happens.  
          Suggestion is to use nginx which uses keep-alive and stores encrypted session key 

          How SSO work ? 
            https://www.youtube.com/watch?v=O1cRJWYF-g4
            
            Two ways 
              using SAML
                - uses XML 
                - uses public key encryption 
              Open id connect
                - uses json doc 
                - which uses token
          
          Oauth 2.0 work ? 
            https://www.youtube.com/watch?v=CPbvxxslDTU

            Related to above 
            How payment gateway work ?
              https://www.youtube.com/watch?v=GUurzvS3DlY

  Networks 
    HTTP over TCP/IP 
      https://www.goanywhere.com/blog/http-vs-tcp-whats-the-difference
      In the case of HTTP which applies at layer 7, before a client and server can exchange an HTTP request/response, they must establish a TCP connection first. Therefore, HTTP relies on the TCP standard in order to successfully do its job.

      HTTP 1.0, 1.1 and 2.0
        https://www.youtube.com/watch?v=a-sBfyiXysI
        1.0 -> tcp handshake all the time
        1.1 -> keep alive, persistent conenection avoids handshake
        2.0 -> multiple streams can go through 1 tcp connection
        3.0 -> Quic which uses UDP
        https://www.linkedin.com/posts/gkcs_http3-systemdesign-networkprotocols-activity-7041095963335139329-uV44/?utm_source=share&utm_medium=member_desktop 

    DNS
      https://www.youtube.com/watch?v=27r4Bzuj5NQ
      queries from browser go to DNS resolver (ISP, Cloudfare, Google) which fetches authoritative name server in hierarchial fashion.
      DNS lookups are cached at client machine, resolver 

  Physical cores, Virtual cores and Logical cores
    https://www.youtube.com/watch?v=O2g6381An_k 

  Processes vs Thread
    https://www.youtube.com/watch?v=4rLW7zg21gI 
      Process is responsible for executing set of instructions from an application
      Process will contain multiple threads


  Logging (errors), Metrics Monitoring (system level, business) and automated Deployment
    Logging (errors)
      - datadog
      - logging errors to trigger alerts, sev
    Metrics Monitoring (system level, business)
      - datadog, 
    Alerting
      - datadog
    Continuous integration
        develop -> commit -> build -> test ->  deploy
      https://blog.inedo.com/continuous-integration-performance-testing-best-practices

  Failure/Error handling
    Common techniques are retry the processing for queue consumer or offload to another server 
    try maintaining the commit log
    explore event sourcing technique

  Verify integrity through blockchain
    https://www.youtube.com/watch?v=SSo_EIwHSd4 


  Event sourcing
      https://www.confluent.io/blog/event-sourcing-cqrs-stream-processing-apache-kafka-whats-connection/
      https://bytebytego.com/courses/system-design-interview/digital-wallet
    One design philosophy that systematically answers those questions is event sourcing, which is a technique developed in Domain-Driven Design (DDD) [9].

  Using LSMTree + SSTable are efficienct for heavy writes and heavy reads on noSQL databases. B tree is not
      Great video : https://www.youtube.com/watch?v=I6jB0nM9SKU 
      Good read : https://rahulpradeep.medium.com/sstables-and-lsm-trees-5ba6c5529325
      This technique is used by Cassandra, RocksDB, Google BigTable, Apache HBase
      MongoDB can be tuned to use LSM treee
    
  Algo if element is the member of the set
    Use Bloom filter
      https://www.youtube.com/watch?v=V3pzxngeLqw
      A bloom filter is a space-efficient probabilistic technique to test if an element is a member of a set. Refer to the reference material [2] for more details.
      Applications
        key value store to check in SSTable
        crawlers to check if url in malicious 
        CDN if page is in cache
  
  Clock synchronization amongst different servers in distributed systems
    https://www.youtube.com/watch?v=f1hlCZB0GDA 
    - Use network time protocol 

  Dynamic rendering to allow search engines to parse content
    https://developers.google.com/search/docs/crawling-indexing/javascript/dynamic-rendering 
    Dynamic rendering is a workaround and not a recommended solution, because it creates additional complexities and resource requirements.

  Scale through Kafka
    https://bytebytego.com/courses/system-design-interview/metrics-monitoring-and-alerting-system
    There are a couple of ways that we can leverage Kafka’s built-in partition mechanism to scale our system.
      Configure the number of partitions based on throughput requirements.
      Partition metrics data by metric names, so consumers can aggregate data by metrics names.
      Further partition metrics data with tags/labels.
      Categorize and prioritize metrics so that important metrics can be processed first - possible with kafa

  Scale map reduce operations 
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation 
    If you are interested in the details, please refer to reference material [20]. Aggregation service is horizontally scalable by adding or removing nodes.
    Question is how you increase the throughput ? 
        1. assign each thread in the server
        2. deploy aggregation service nodes on resource providers like Apache Hadoop YARN [21]
      Option 1 is easier to implement and doesn’t depend on resource providers. In reality, however, option 2 is more widely used because we can scale the system by adding more computing resources.
  Using star schema as pre-filtered form 
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation
    To support data filtering like “show me the aggregated click count for ad001 within the USA only”, we can pre-define filtering criteria and aggregate based on them. This technique is called the star schema [11], which is widely used in data warehouses. The filtering fields are called dimensions. 
    A limitation with this approach is that it creates many more buckets and records, especially when we have a lot of filtering criteria.


  Combine batch processing and streaming with one service 
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation
    For a system that contains two processing paths (batch and streaming) simultaneously, this architecture is called lambda [14]. A disadvantage of lambda architecture is that you have two processing paths, meaning there are two codebases to maintain. Kappa architecture [15], which combines the batch and streaming in one processing path, solves the problem. The key idea is to handle both real-time data processing and continuous data reprocessing using a single stream processing engine. 

  Process delayed events 
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation
    One way to mitigate this problem is to use “watermark” (the extended rectangles in Figure 14), which is regarded as an extension of an aggregation window. This improves the accuracy of the aggregation result. By extending an extra 15-second (adjustable) aggregation window, window 1 is able to include event 2, and window 3 is able to include event 5.

  Aggregation window
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation
    According to the “Designing data-intensive applications” book by Martin Kleppmann [16], there are four types of window functions: tumbling (also called fixed) window, hopping window, sliding window, and session window. We will discuss the tumbling window and sliding window as they are most relevant to our system.

  Fault tolerance systems
    - retry logic by storing last online state in S3 / KV store
    - save computational work in snapshots storage for low latency (https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation)

  Monitoring metrics
    total Latency and also at each stage
    Queue size if used
    system resources : CPU, disk, JVM, etc.

  Reconcilliation for data consistency
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation
    Reconciliation means comparing different sets of data in order to ensure data integrity. Unlike reconciliation in the banking industry, where you can compare your records with the bank’s records, the result of ad click aggregation has no third-party result to reconcile with.

  Alternative designs for aggregation
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation 
    In a generalist system design interview, you are not expected to know the internals of different pieces of specialized software used in a big data pipeline. Explaining your thought process and discussing trade-offs is very important, which is why we propose a generic solution. Another option is to store ad click data in Hive, with an ElasticSearch layer built for faster queries. Aggregation is usually done in OLAP databases such as ClickHouse [24] or Druid [25]. Figure 29 shows the architecture.


  Line protocol
    https://bytebytego.com/courses/system-design-interview/metrics-monitoring-and-alerting-system
      CPU.load host=webserver01,region=us-west 1613707265 76
      CPU.load host=webserver01,region=us-west 1613707265 83

      The average CPU load could be computed by averaging the values at the end of each line. The format of the lines in the above example is called the line protocol. It is a common input format for many monitoring software in the market. Prometheus [6] and OpenTSDB [7] are two examples.

          A metric name	String
          A set of tags/labels	List of <key:value> pairs
          An array of values and their timestamps	An array of <value, timestamp> pairs

  Push vs Pull model
      https://bytebytego.com/courses/system-design-interview/metrics-monitoring-and-alerting-system 
      Metrics monitoring : 
        Examples of pull architectures include Prometheus.
        Examples of push architectures include Amazon CloudWatch [16] and Graphite [17].

      Easy debugging: pull
      Health check : pull
      Short lived jobs : push
          Some of the batch jobs might be short-lived and don’t last long enough to be pulled. Push wins. But This can be fixed by introducing push gateways for the pull model [22].
      Firewall or complicated network setups : push
      Performance : Push
        since push uses UDP, it wins vs pull which relies on TCP
      Data authenticity	: Pull
        zookeeper can provide valid servers to pull from
      Fault tolerant and reliability : Pull
        since failed messages can be queried again

  gRPC
    For production systems, inter-service communication often employs a modern and high-performance remote procedure call (RPC) framework like gPRC. There are many benefits to using such frameworks. To learn more about gPRC in particular, check out [3].

  Avoid Risk of double booking in transaction systems like hotel rooms, payment systems
    There are two common approaches to solve this problem:

      Client-side implementation. A client can gray out, hide or disable the “submit” button once a request is sent. This should prevent the double-clicking issue most of the time. However, this approach is not very reliable. For example, users can disable JavaScript, thereby bypassing the client check.

      Idempotent APIs. Add an idempotency key in the reservation API request. An API call is idempotent if it produces the same result no matter how many times it is called. Figure 8 shows how to use the idempotency key (reservation_id) to avoid the double-reservation issue. The detailed steps are explained below.

  Different types to avoid race conditions during concurrency
    1. Pessimistic locking 
        - as name suggests, it locks the record while read + update
        - good when data contention is high
        - slows down performance
    2. Optimistic locking
        - has validation check based on version number. So no locking is needed. 
        - good when data contention is low and improves performances
        - bad when data contention is high 
    3. database constraint
        - add constraint at table level
        - same as Optimistic and its easier to implement

  CI/CD practices
    https://www.youtube.com/watch?v=42UP1fxi2SY
    - CI stands for continuous integration and is more common. Its the practice of using automation to enable teams to merge code changes in shared repository. Each commit triggers an automated workflow on the CI server that builds and runs series of tests to make sure commit is safe to merge into main branch.
      - CI process : code -> build -> test -> release
      - tools for CI - github
      - tools to manage CI process: code (github), build (gradle, webpack, github actions), test (jest), release (jenkins, buildkite)

    - CD stands for continuous deployment but it is hard and many companies only apply to stateless systems. Needs good production monitoring for CD like datadog. Blue green deployments is common. Canary deployment is also possible for products with 100 million users.
    - CD is hard for database backend clusters or websocket cluster. So deployment process is manual here and needs dedicated platform team
      - CD process : code -> build -> test -> acceptance -> deploy in production
      - CD tools : github actions, jenkins, argoCD for kubernetes 

  How to provison resources in the could
    https://www.youtube.com/watch?v=tomUWcQ0P3k
    Use terraform as Infrastructure as code

  
  How to store password in the database
    https://www.youtube.com/watch?v=zt8Cocdy15c
    use hashing + salt

  Bare metal, VMs and containers
    https://www.youtube.com/watch?v=Jz8Gs4UHTO8
    VMs have hypervisor to run the guest OSes
    Containers have container agent (eg., docker) to run the application in its own environment but uses instance/host OS to operate and have faster operations and more flexibility but suffers from security sharing common instance/host OS. To achieve security, you can have a container inside the VM but it looses flexibility now. 

=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================



Distributed systems today and Benchmarking on common systems

    Map Reduce
      https://www.youtube.com/watch?v=MAJ0aW5g17c (awesome)
        Example of GFS performing map function on worker servers and reduce using worker servers co-ordinated by master
      The MapReduce framework is a good option to aggregate ad click events. The directed acyclic graph (DAG) is a good model for it [9]. The key to the DAG model is to break down the system into small computing units, like the Map/Aggregate/Reduce nodes (https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation)
      Hotspot issue in map reduce
        supported by resource manager (https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation)

    Zookeeper 
     - centralized configuration, key value store for state and also co-ordination service like selecting leader/master
     - can perform as a shard manager to find out the shard based on key ( https://kousiknath.medium.com/all-things-sharding-techniques-and-real-life-examples-in-nosql-data-storage-systems-3e8beb98830a#:~:text=You%20can%20use%20some%20configuration,directly%20talk%20to%20the%20shard. )
     - The number of partitions and addresses of all Redis nodes can be stored in a centralized place. We could use Zookeeper [4] as a highly-available configuration storage solution. (https://bytebytego.com/courses/system-design-interview/digital-wallet)
     - Apache Zookeeper [7] is a popular open-source solution for service discovery. It registers all the available chat servers and picks the best chat server for a client based on predefined criteria. (https://bytebytego.com/courses/system-design-interview/design-a-chat-system)
     - There are many service discovery packages available, with etcd [4] and Zookeeper [5] among the most popular ones. Our need for the service discovery component is very basic. https://bytebytego.com/courses/system-design-interview/nearby-friends 
        - Under the “Key” mentioned in point 1, we store a hash ring of all the active Redis pub/sub servers in the service discovery component (See the consistent hashing chapter in Volume 1 of the System Design Interview book or [6] on details of a hash ring). The hash ring is used by the publishers and subscribers of the Redis pub/sub servers to determine the pub/sub server to talk to for each channel. 
      https://ramcloud.atlassian.net/wiki/spaces/RAM/pages/6848719/ZooKeeper+Performance 
      

    Kafka
      https://www.youtube.com/watch?v=UNUz1-msbOM
      latency : 1 ms
      Optimized on consumer side due to append-only log and zero copy (avoids copying into socket buffer)
      Excatly once delivery is hard but Yelp implements it. Check it out https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation 
        To achieve “exactly-once” processing, we need to put operations between step 4 to step 6 in one distributed transaction. A distributed transaction is a transaction that works across several nodes. If any of the operations fails, the whole transaction is rolled back.


    Streaming vs Batching systems 
     https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation
     Batch : MapReduce
     Stream : Flink (also mentioned in https://bytebytego.com/courses/system-design-interview/metrics-monitoring-and-alerting-system )

  Cache benchmarking

    Azure Redis Cache : 
        53 GB, with 99.9% availability (https://github.com/Huachao/azure-content/blob/master/articles/redis-cache/cache-faq.md)
        230 us (https://redis.io/docs/management/optimization/latency/)
        Redis QPS - 50K https://redis.io/docs/management/optimization/benchmarks/
        1 million TPS - https://bytebytego.com/courses/system-design-interview/digital-wallet 
        Redis also privides sorted set data structure. Our leaderboard use case maps perfectly to sorted sets. Internally, a sorted set is implemented by two data structures: a hash table and a skip list [1]. The hash table maps users to scores and the skip list maps scores to users. In sorted sets, users are sorted by scores. (https://bytebytego.com/courses/system-design-interview/real-time-gaming-leaderboard)
        Sorted set is used in Rate limiter sliding window design which fetches based on timestamp range and avoids race conditions. 
        Redis cluster also supports sharding with hash slot ( different from consistent hashing)
        Redis cluster uses master-replica model
        Redis Cluster does not guarantee strong consistency
        Max Size of each redis instance from AWS : 500 GB https://aws.amazon.com/elasticache/pricing/?nc=sn&loc=4 
        Sorted Set - https://redis.io/docs/data-types/sorted-sets/
        How redis works 
          https://www.youtube.com/watch?v=5TRFpFBccQM

    CDN
        Let us use Amazon’s CDN CloudFront for cost estimation (Figure 2) [3]. Assume 100% of traffic is served from the United States. The average cost per GB is $0.02. For simplicity, we only calculate the cost of video streaming.

          5 million * 5 videos * 0.3GB * 0.02 = 150,000 per day.

        Looks unrealistic : 
          https://cloud.google.com/cdn/pricing 
          5 million requests with 500 GB cache ~ 40$ per month

  SQL DB benchmarking - Relational
        1. MySQL benchmarking
          - Indexed Read
              a. with primary key reads which is already indexed
                (https://dev.mysql.com/blog-archive/mysql-connection-handling-and-scaling/)
                Recommend 4 * number of cores parallel for ~ 200 us based on simple primary key look ups. For example, 120 (~4 * 32) parellel requests for 32 cores will take 200 us
                1K requests on 32 will take ~ 1ms for simply select query
          
          - Write
            7 K writes/s for 48 core http://minervadb.com/wp-content/uploads/2020/10/MySQL-8-Performance-Benchmarking-on-Amazon-EC2.pdf 
            impact of write performance on indexing
              4 times slower : https://logicalread.com/impact-of-adding-mysql-indexes-mc12/#.Y__7d-zMLuU 
              ~1 K writes/s for 48 core

          - General benchmarking
            Today, a relational database running on a typical data center node can support a few thousand transactions per second.


          - Max size set by MySQL
            256 TB (https://dev.mysql.com/doc/mysql-reslimits-excerpt/8.0/en/table-size-limit.html#:~:text=You%20are%20using%20a%20MyISAM,2567%20%E2%88%92%201%20bytes)
            AWS limit : 64 TB
            According to Amazon Relational Database Service (RDS) [12], you can get a database server with 24 TB of RAM.

          Some facts
          - MySQL client <-> server is socket based connection. Check why ?
          - Max connection limit for MySQL = 100 K
          - per connection -> one user thread
          - size of user thread depends on THD connection data structure which is per connection ~ 10 MB 
          - max THD ~ 10K 
          - So recommended min size of your MySQL = 10 MB * 10 K = 100 GB ??

          - MySQL sorting (https://www.pankajtanwar.in/blog/what-is-the-sorting-algorithm-behind-order-by-query-in-mysql)
              External merge sort (quick sort + merge sort) if data doesn’t fits into the memory
              Quick sort, if data fits into the memory and we want all of it
              Heap sort, if data fits into the memory but we are using LIMIT to fetch only some results
              Index lookup (not exactly a sorting algorithm, just a pre-calculated binary tree)

          - MySQL query cache (https://docs.oracle.com/cd/E17952_01/mysql-5.1-en/query-cache.html)
              As of MySQL 5.1.63, the query cache is not supported for partitioned tables, and is automatically disabled for queries involving partitioned tables. The query cache cannot be enabled for such queries. 

          - MySQL sharding (https://stackoverflow.com/questions/1610887/how-to-partition-mysql-across-multiple-servers)
              this is different from mysql partitioning (https://vertabelo.com/blog/everything-you-need-to-know-about-mysql-partitions/)
          
          - Moreover, MySQL involves no standard implementation for sharding. (https://kinsta.com/blog/mongodb-vs-mysql/)

          - MySQL indexing 
              https://www.youtube.com/watch?v=YuRO9-rOgv4 using B tree
              B tree performance : https://www.youtube.com/watch?v=FgWbADOG44s 
              Its inefficient as compared to B tree for writes : https://www.youtube.com/watch?v=I6jB0nM9SKU 

          - MySQL replica sync
              https://serverfault.com/questions/30605/how-fast-is-mysql-replication
              MySQL replication happens as close to real-time as possible (AWS has <200 ms SLA), as limited by disk and network I/O. The slaves open a socket to the master, which is kept open. When a transaction occurs on the master, it gets recorded in the binlog, and is simply replayed on the slave(s). If the socket between master and slave is interrupted, the binlog is replayed for the slave upon the next successful connection.


          - Multi-region failover time for AWS RDS : 60-100s 
              https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZSingleStandby.html

          - Replication lag for AWS RDS : < 100 ms 
              https://www.bluematador.com/docs/troubleshooting/rds-replica-lag#:~:text=Replication%20lag%20measures%20how%20far,than%20100ms%20of%20replication%20lag. 


          - Practical
              how MySQL gurantees ACID : https://www.youtube.com/watch?v=0OYFsJ1-1YA
              Nice theoretical : https://www.youtube.com/watch?v=clPPKgYJC10 
                Atomicity : begin trans --> comitt statement
                Consistency : integrity constraints (guessing)
                Isolation : concurency control subsytem. done through locks
                Durability : ? 

            



    NoSQL value DB benchmarking
        1. Timeseries : OpenTSDB / InfluxDB
              8 cores and 32GB RAM can handle over 250,000 writes per second, greater than 1 M series
              (https://bytebytego.com/courses/system-design-interview/metrics-monitoring-and-alerting-system)

              Performance optimization
                https://bytebytego.com/courses/system-design-interview/metrics-monitoring-and-alerting-system
                  According to a research paper published by Facebook [24], at least 85% of all queries to the operational data store were for data collected in the past 26 hours. If we use a time-series database that harnesses this property, it could have a significant impact on overall system performance. If you are interested in the design of the storage engine, please refer to the design document of the Influx DB storage engine [26].
                  - Storage : Store only delta for timestamps
                  - Storage and querying : Downsampling
                  - use cold storage for old data

        2. Object storage / cold storage benchmarking
            S3 Standard is designed for 99.99% data availability and durability of 99.999999999% of objects across multiple Availability Zones in a given year. AWS S3 provides a great performance. It automatically scales to high request rates, with a very low latency of 100–200 milliseconds.Your application can achieve at least 3,500 PUT/COPY/POST/DELETE and 5,500 GET/HEAD requests per second per prefix in a bucket (https://aws.plainenglish.io/optimize-your-aws-s3-performance-27b057f231a3)
            Another option is to store the data in Amazon S3 using one of the columnar data formats like ORC [5], Parquet [6], or AVRO [7]. We could put a cap on the size of each file (say, 10GB) and the stream processor responsible for writing the raw data could handle the file rotation when the size cap is reached. (https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation)


        3. Cassandra

              100s video : https://www.youtube.com/watch?v=ziq7FUKpCS8
              Slower version of 100s : https://www.youtube.com/watch?v=YjYWsN1vek8 
              
              Not super helpful though : 
                Cassandra data model : https://www.youtube.com/watch?v=X-_vS8q4nu4&list=PLGkHHA2RcrgeV35CBtIlUjiXJzVXLxMbL&index=3
                How Cassandra data is  stored :  https://www.youtube.com/watch?v=69dLARZxIVw&list=PLGkHHA2RcrgeV35CBtIlUjiXJzVXLxMbL&index=4 
                How Cassandra read / write data : https://www.youtube.com/watch?v=t276nhhkkI8&t=523s
              
              Cassandra indexing
                Paritioning : https://www.youtube.com/watch?v=Np5RJpCiCzM
                Clustering used as sort key : https://www.youtube.com/watch?v=OCakxrzwuU4 
                  Remember data in cassandra on disk supports SSTable which is sorted string table.
                  So searching could be done in logN times like relational or mongoDB

              Practical 
                    Cassandra indexing (partition + clustering which is sort key) : https://www.youtube.com/watch?v=S9rmf4X7E_E

              Garbage collection
                4.0 uses Z GC instead of G1 GC (java8 to java 16)

              Cassandra and map-reduce
                https://subscription.packtpub.com/book/data/9781787127296/1/ch01lvl1sec5/mapreduce-and-spark
                Unlike MongoDB, Cassandra does not offer built-in MapReduce capabilities. But it can be integrated with Hadoop in order to perform MapReduce operations across Cassandra data sets, or Spark for real-time data analysis. 

              Cassandra performance on writes + reads on indexes 
                - LSM tree + SS tables
                Great video : https://www.youtube.com/watch?v=I6jB0nM9SKU 
                Good read : https://rahulpradeep.medium.com/sstables-and-lsm-trees-5ba6c5529325 
                B Tree vs LSM tree technique - https://www.youtube.com/watch?v=4z7-SrDiBoU

              Consistent hashing
                If we add a new node to the cluster, it automatically rebalances the virtual nodes among all nodes. No manual resharding is required. See Cassandra’s official documentation for more details [22]. - https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation 
                
              Benchmarking
                - On Cheap heardware https://benchant.com/blog/cassandra-4-performance
                  m5.large ( 2 core, 8 GB) 
                  Read : 7 K ops/s
                  Write : 7 K ops/s
                  Read Latency : ~10 ms
                  Write Latency : ~7 ms

                - Expensive hardware https://www.scylladb.com/2021/08/19/cassandra-4-0-vs-cassandra-3-11-comparing-performance/
                  i3.4xlarge (16 vCPUs, 122 GB)
                   Read : 30 K ops/s
                   Write : 20 K ops/s
                   Read Latency : ~10 ms
                   Write Latency : ~10 ms

        4. MongoDB
              - How Mongo DB search works : https://www.youtube.com/watch?v=tSgPhxZdhLk&t=96s 
                  using index in B tree
              - MongoDB supports range-based or hash-based sharding - https://kinsta.com/blog/mongodb-vs-mysql/
              - For aggregations, Instead of map-reduce, you should use an aggregation pipeline. Aggregation pipelines provide better performance and usability than map-reduce. https://www.mongodb.com/docs/manual/core/map-reduce/
              - How Mongo DB sharding works : https://kinsta.com/blog/mongodb-vs-mysql/ 
              - Practical
                  set up mongo based sharding https://www.youtube.com/watch?v=mjSNKjTzeao 
                  mongoDB gridFS https://www.youtube.com/watch?v=mZE3aBdr010 

        6. Dynamo DB
            Nice intro in https://bytebytego.com/courses/system-design-interview/real-time-gaming-leaderboard

            DynamoDB is a fully managed NoSQL database that offers reliable performance and great scalability. To allow efficient access to data with attributes other than the primary key, we can leverage global secondary indexes [16] in DynamoDB. A global secondary index contains a selection of attributes from the parent table, but they are organized using a different primary key. 
            So Every global secondary index must have a partition key, and can have an optional sort key. The index key schema can be different from the base table schema. 

            DynamoDB splits data across multiple nodes using consistent hashing.


        7. S3

        8. Neo4j

        

  Attempt to standardized DB selection criteria 
      1. MySQL vs noSQL 

            When MySQL
            if ACID, 
              then MYSQL (high confidence)
            if reasonable size (< 1 TB) not expected to scale rapidly,
              if heavy reads (reading from read replicas is faster) 
                if low writes 
                  then MySQL (high confidence)
                if heavy writes (else have to keep synchronizing and index making)
                  then MySQL (low confidence)
            If db needs rapid scale (size keeps growing)
              if manual sharding is needed ( say by user id )
                if sharding has all related rows (try to denormalize)
                  if there are less aggregations 
                    then MySQL (medium confidence)
                  if there are more aggregations 
                    then MySQL (low confidence since aggregations with sharding could be better achieved with noSQL DBs like MongoDB, Cassandra)
            If db needs better search performance (not full text search)  
              if index-ing on fixed columns,
                then MySQL (high confidence)
              if db experience heavy writes
                then MySQL (low confidence since indexes increases write latency) 

      2.  MySQL vs MongoDB

      3.  MongoDB vs Cassandra
            https://www.youtube.com/watch?v=3z2EzILA3Rk 

                Cassandra                          vs               MongoDB 
            column data model                                   json document data model
            no config server(ring structure)                    mongo master, slave and mongo config servers for replication
            high availability due to multiple masters           master -> slave takes time
            accept writes in parallel                           write capacity is limited since they just go to master
            similar to SQL                                        based on json formatting

            When mongo DB
              query also based on secondary indexing and flexible querying
              built in data aggregation framework
              read-heavy workload

            When Cassandra 
                query based on primary key indexing 
                100% uptime guarantee due to replication and inconsistency resolution
                high write speed
                language support for SQL
                write-heavy, read-heavy workload
                eventual consistency (as per bytebytego - https://bytebytego.com/courses/system-design-interview/design-a-key-value-store )

     

      Open questions
            1. Why is MySQL better for read heavy low write workload ? answered above
            2. MySQL is better for ACID systems and structured ? How ? answered above
            2. How MySQL syncs with its replicas ? answered above
            2. Why is Cassandra (noSQL) better for read heavy write heavy workload ? answered above
            3. Aggregation on sharded MySQL needs Application level handling vs Cassandra or HBase(Column) can handle this since they are built on top of distributed systems . Fact and derived above
            4. How MySQL indexing works ? answered above
            5. Cassandra benchmarking ? answered above
            7. Time taken from master to slave - MySQL, MongoDB ? MySQL ( 200 ms aws)
            9. Refer NTP ? answered above
            8. MongoDB benchmarking ?
            6. Study about graphdbs ? 

 Operation system
    User level threads vs Kernel level threads
      https://www.youtube.com/watch?v=_5q8ZK6hwzM

 
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================


References

Dump : https://coursehunters.online/t/educative-io-design-gurus-grokking-the-system-design-interview-part-5/584
Quick read : https://github.com/Jeevan-kumar-Raj/Grokking-System-Design

    
- Load balancing
    Resources
      https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/load-balancing.md
      https://www.cloudflare.com/learning/performance/types-of-load-balancing-algorithms/
      https://igotanoffer.com/blogs/tech/load-balancing-system-design-interview
    Static load balancing - round robin, weight round robin, IP hash
    Dynamic load balanacing - least connection, least resource, least response time, least bandwidth
    When to use Static ?
      If the server pool and the requests are both homogeneous, and there is only one balancer. Stateless servers handling single api can use static load balancer
      
    When to use Dynamic ?
      if the requests are heterogenous, Least Load is helpful to prevent servers from being intermittently overloaded.
      
    What are Hardware load balancers ?
      They have high performant hardware resources like L4 and L7. 
      Read about L4 and L7 here https://levelup.gitconnected.com/l4-vs-l7-load-balancing-d2012e271f56
      
    What are Software load balancers ?
      They run on standard servers and are less hardware optimized, but cheaper to set up and run. Example, Nginx or HAProxy. For Nginx 100s video, 
      refer https://www.youtube.com/watch?v=JKxlsvZXG7c. Nginx can serve routing to different servers, rate limiting, handle spikes,
      reverse proxy, security, cache, etc. 
      
    When to use Software or Hardware ?
      Tip : Since software load balancing can run on ordinary hardware and supports, always prefer software load balancer. Example Nginx
       
      
    What is proxy server, reverse proxy and API Gateway ? How is different from load balancer
      proxy vs reverse proxy vs load balancer : https://www.youtube.com/watch?v=MiqrArNSxSM
      Proxy : just protects the client side
      Reverse Proxy : protects the server by serving as proxy for all backend services - routing, rate limitng, load balancing
      API gateway : rate limiting, routing, handle spikes
      Load balancer : only performs load balancing
      
      So Reverse proxy can perform both API Gateway and Load Balancing. Example nginx.
      A load balancer can never be API gateway or reverse proxy.
      
     Always choose Nginx ? Why ?
       Has triats of load balancing + reverse proxy + API gateway
         - supports load balancing
         - supports request forwarding based on different paths like api gateway
         - supports reverse proxy 
         - supports rate limiting
         - supports caching
         - supports request grouping
         - supports secure auth SSL. Also does optimizations with keep alive connection and cache to avoid SSL handshake - https://docs.nginx.com/nginx/admin-guide/security-controls/terminating-ssl-http/ 
         Also a good read https://www.nginx.com/blog/http-keepalives-and-web-performance/
       Nginx supports L7
================================================================

      
  - Caching
    Resources
      https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/caching.md
      Distributed cache on Application server VS Global cache like Redis, (mostly preferred)
      CDN is another form of cache for static content but its often expensive
      
          
       What are different caching strategies ? 
          https://codeahoy.com/2017/08/11/caching-strategies-and-how-to-choose-the-right-one/
          Cache-Aside (application server has cache aside like Redis, Memcache and DB separately)
            - Pros : logic controlled by application server, resilent to cache failures, data model in cache vs db could be different
            - Cons : stale data in cache for db writes
          Read-Through Cache (application server reads from cache only)
            - Pros : logic controlled by cache, read-heavy, good consistency when combined with write through 
            - Cons : needs data model to be consistent, first time data always results in cache miss
            Application : autocomplete suggestion to read from trie cache - https://bytebytego.com/courses/system-design-interview/design-a-search-autocomplete-system 

          Belpw are Cache writes invalidation policy 

          d through (data is written to cache and synced with storage)
            - Pros : fast retreival and data consistent systems
            - Cons : slow writes though
          Write around (data is written to storage, not cache)
            - Pros : Saves write operation on the cache
            - Cons : recently written data creates a cache miss and higher latency.
          Write back (data is written to cache only, then synced later to storage)
            - Pros : fast retreival, low latency read / writes
            - Cons : Risk of data loss
            
        Real applications of 
          1. read-through, write-through for high consistency
                DynamoDB Accelerator (DAX) for dynamoDB
          2. read-through, write-around for high performance for situations where data is written once and read less frequently or never.
                real-time logs, chatroom messages
          3. cache-aside, write back cache to absorb spikes during peak load
                custom applications using redis
          4. write back cache
                InnoDB which is relational database storage engine. Queries are first written to memory and eventually flushed to the disk.
                
                
================================================================
    - Sharding / Partitioning 
        Resources
          https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/sharding.md
          https://coursehunters.online/t/educative-io-design-gurus-grokking-the-system-design-interview-part-5/584
          Horizontal, Vertical and Directory based paritioning
            Directory based paritioning has work around to solve some challenges with Horizontal and Vertical?
          What's the best Partitioning criteria ?
            Consitent hashing which is combination of hash and list based partitioning
          Commom problems with Sharding / Partitioning
            Joins -> Denormalization
            Referential Integrity (primary key -> foreign key. look at image in https://en.wikipedia.org/wiki/Referential_integrity)
            Hot shard problem needs rebalancing
              How to rebalance ? 
              It would take downtime, check directory based partitioning as per our educative.io resource.
              But consistent hashing can solve this problem better - https://medium.com/nerd-for-tech/consistent-hashing-6524e48ac648
              Great guide above - check consistent hashing with gossip protocol so that each partition knows where to fetch data from db
          Applications of consistent hashing ?
          Apache Cassandra, Dynamo DB
 
 ================================================================

    - Indexing
        Resources
          https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/indexes.md
          What is a database index ? 
            https://www.codecademy.com/article/sql-indexes
          Pros
            helps in speeding up the search 
          Cons
            lowers write/update/delete performance by 4 times
          When to use indexes ?
            In the case of data sets that are many terabytes in size but with very small payloads (e.g., 1 KB), 
            indexes are a necessity for optimizing data access. Finding a small payload in such a large dataset can be a real challenge since
            we can’t possibly iterate over that much data in any reasonable time. Furthermore, it is very likely that such a large data set is 
            spread over several physical devices—this means we need some way to find the correct physical location of the desired data. 
            Indexes are the best way to do this.
            
   ================================================================

     - Proxy 
        Resources
          https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/proxies.md
          
          Usage : 
          filter requests, log requests, cache, encryption and most important batch request. Further, it can get smarter to o collapse requests for data that is spatially close together in the storage (consecutively on disk). This strategy will result in decreasing request latency. 
          For example, let’s say a bunch of servers request parts of file: part1, part2, part3, etc. We can set up our proxy in such a way 
          that it can recognize the spatial locality of the individual requests, thus collapsing them into a single request and reading complete file, 
          which will greatly minimize the reads from the data origin.
          
          Proxy are of two types 
          Client proxy to protect the clients
          Server proxy to protect the servers. Also called reverse proxy
          
          Should we use proxy then?
          Only use proxy to protect the client.
          For server side, Always Nginx since its open source and supports both reverse proxy + load balancing + API gateway.
          
          
   
   ==============================================================================

          Queues
          
            Resource :
            - https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/queues.md
            
            When to use queue :
            Queues are implemented on the asynchronous communication protocol, meaning when a client submits a task to a queue they 
            are no longer required to wait for the results; instead, they need only acknowledgment that the request was properly received.
            
            Queues are also used for fault tolerance as they can provide some protection from service outages and failures. For example, 
            we can create a highly robust queue that can retry service requests that have failed due to transient system failures
            
            When not to use queue :
            When client expects respone in real-time
            
            Example of queues : 
             RabbitMQ and Kafka (which is open source)
             
  ====================================================================================
  
        Redundancy and Replication
        
          Resource : 
          https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/redundancy.md
          
          When to use Redundant system :
          Always. its a key concept of distributed system.
          Always prefer shared nothing architecture so that each node can operate independently and can scale.
          
          
    ====================================================================================
        SQL vs NoSQL
        
          Resource : 
          https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/sql-vs-nosql.md
          
          SQL 
          Relational databases store data in rows and columns. Example, MySQL, Oracle, MS SQL Server, SQLite, Postgres
          
          NoSQL 
          Key-value :  Example, DynamoDB, Redis, Memcache
          Document DB : Example, MongoDB, 
          Wide-Column Database : Example, HBase, Cassandra - https://hevodata.com/learn/columnar-databases/
          Graph Databases : Example, Neo4j
          
          Differences between both 
          Storage : SQL is tables but NoSQL has different storage models
          Schema : changing schema with SQL is possible but requires whole database modification
          Querying : using SQL for SQL dbs. 
          Scalability : SQL is vertically scalable and possible to scale it horizontally but has limitations. NoSQL is horizontally scalable
          Reliability or ACID : Definitely SQL ensures ACID but NoSQL solutions sacrifice ACID compliance for performance and scalability.
          
          When to use SQL
            ACID compliance for e-commerce and finanicial transactions
            Your data is structured and unchanging.
            Often Read heavy and low-write

            
          When to use NoSQL
            - Storing large volumes of data that often have little to no structure. 
            - Making the most of cloud computing and storage. Cloud-based storage is an excellent cost-saving solution 
            but requires data to be easily spread across multiple servers to scale up. 
            - Rapid development. NoSQL is extremely useful for rapid development as it doesn’t need to be prepped ahead of time. 
            
          What about write performance ? 
          noSQL has better write performance due to SSTable + LSM tree implementation. Example, Cassandra
          

            
            
  ====================================================================================
  
    CAP Theorem
    Resource : 
    https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/cap-theorem.md
    
    CAP theorem states that it is impossible for a distributed software system to simultaneously provide more than two out of three of 
    the following guarantees (CAP): Consistency, Availability and Partition tolerance.
    
    We can only build a system that has any two of these three properties. Because, to be consistent, all nodes should see the same set of updates 
    in the same order. But if the network suffers a partition, updates in one partition might not make it to the other partitions before a client 
    reads from the out-of-date partition after having read from the up-to-date one. The only thing that can be done to cope with this possibility is to stop serving requests from the out-of-date partition, but then the service is no longer 100% available.

    When to choose consistency over availability ? 
      Banking, Payment systems
    
    When to choose availability over consistency   ? 
      Most distributed system use cases like Google Maps, Twitter, etc.
      
    Since reliability consists of both consistency and availability, ASK YOUR interviewer what it means for system to be 99.99% reliable
    
    
   ====================================================================================
 
    Consistent Hashing
    
    Resource 
      https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/consistent-hashing.md
      Recommended ones 
        https://medium.com/nerd-for-tech/consistent-hashing-6524e48ac648 - Explains well about rebalancing
        https://bytebytego.com/courses/system-design-interview/design-consistent-hashing
        
      How does it work ? 
        Hashing is done in the range where it maps the key to the integer in that range. Example 0 -> 255 are the integers placed in ring form such that values are wrapped around.
        
        1. the servers are mapped to the integers in that range
        2. to map key to a server, simply hash the key to the integer in that range and move clockwise till you find the server (could be binary search)
        
        Now how this is better :
        1. adding a server : say S1 is added at position 20 and is near S2 at position 25. Then keys from before 20 wuld map to S1.
        2. removing a server : say S1 is removed at position 20 and was near S2 at position 25. Then  all keys even before 20 would map to S2. 
        3. uniform distribution : add “virtual replicas”. Instead of mapping each server to a single point on the ring, 
            we map it to multiple points on the ring, i.e. replicas. 
        4. easy to rebalance : when server is added or removed, only its next clockwise neighbouring server is affected and requires re-mapping of keys.
        
        
    ====================================================================================
    
    Client-Server Communication
    
      Resource : 
        https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/client-server-communication.md
        
      Types : 
      1. Standard HTTP Web Request : client opens the connection, gets response from the server and terminate the connection 
      2. Ajax Polling : client performs HTTP Web Request above periodically (say every 1 s). May create unecessary empty responses if server is not ready.
      3. Long Polling : client performs HTTP Web Request and waits for long time till response is received (say 1 min). Then sends request again.
      4. Web Socket: persistent connection between a client and a server that both parties can use to start sending data at any time.
      5. SSE :  persistent onnection between a client and a server where server send data to the client but not the reverse
      
      When to use Long Polling vs Web Socket ? 
        https://ably.com/blog/websockets-vs-long-polling
        https://dev.to/kevburnsjr/websockets-vs-long-polling-3a0o
        
        Clearly Websockets have many advantages over long polling and thus are appropriate for many applications which require consistent low latency 
        full duplex high frequency communication such as chat applications and real time applications.
        
        Scaling up 
        Websockets have problems with load distribution due to persistent connection.
        Long polling will have equal load distribution after its long timeout
        
     When to use Web Socker vs Server Sent Events ?
        Websocket for bi-directional communication while SSE for server to client communication
        https://blog.bitsrc.io/websockets-vs-server-sent-events-968659ab0870
        
        WebSockets are widely used and valued in technological solutions such as real-time polling, chat, media players, multiplayer games, etc.
        Server-Sent Events: There are many applications where sending data from the client isn’t necessary. 
        SSEs are especially useful in status updates, social-media news feeds, push notifications, newsletters, etc.

      Keep alive : 
        https://www.imperva.com/learn/performance/http-keep-alive/
        - improves latency to avoid 3-way handskae and SSL/TLS connections
        - less consumption of network resources to use single connection. This can drop network conjestion




===============================================================

- Key characteristics
    Resources
      https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/key-characteristics.md 
    Scalability, Availability, Reliability, Efficiency and Servicability/Manageability
    -> Remember an Avaiability system does not means Reliable but Reliable system is always available. 

  How to handle burst / spiky reads ? 
    Use Nignx to do request collapsing for similar type of content
    Use queue if content does not need to be delivered real-time
    Other strategies : Data Cache, CDN (https://www.onecloudsystems.com/2016/10/25/how-to-ensure-site-can-handle-traffic-spikes/)

  Pull vs push models
    In Pull approach, the metrics collector needs to know the complete list of service endpoints to pull data from. The good news is that we have a reliable, scalable, and maintainable solution available through Service Discovery, provided by etcd [14], Zookeeper [15], etc., wherein services register their availability and the metrics collector can be notified by the Service Discovery component whenever the list of service endpoints changes. 
    If a server goes down, then you can re-try in the next pull. But here you need dedupe logic or  store the offset in S3 to know what messages to retry.

    In a push model, a collection agent is commonly installed on every server being monitored. Aggregation is an effective way to reduce the volume of data sent to the metrics collector. If the push traffic is high and the metrics collector rejects the push with an error, the agent could keep a small buffer of data locally (possibly by storing them locally on disk), and resend them later.
    If a server goes down or cannot handle burst traffic, then you loose the message.

  Tips to ensure consistency 
    - To maintain data consistency between internal services, ensuring exactly-once processing is very important.
    - To maintain data consistency between the internal service and external service (PSP), we usually rely on idempotency and reconciliation.
    - For replicas, ensure acknowledge only if all replicas respond to read/write update. 

    
   
================================================================================================================================
- Key learnings from system design

 
  
   
         
    

      
    
   
  

  

  
  
  

  
  

  


  




























              






=================================================================================

    
