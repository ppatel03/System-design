Links :

https://bytebytego.com/courses/system-design-interview/back-of-the-envelope-estimation

https://matthewdbill.medium.com/back-of-envelope-calculations-cheat-sheet-d6758d276b05


https://docs.google.com/document/d/1wUCqhVHydWiDk6FJdFLSMpgigNrGcs4OFZg0Wa7JGEw/edit


High level Tips :
- Ask functional requirements first (example, ability to post tweet, view tweet)
- Ask types of users (admin, general) 
- Ask about interaction points - API, UI
- Ask about devices - Mobile or WEB 
    (though need reasoning why you asked this question :) . 
      1. mobile could be low bandwidth network ~ 100 Mbps or 10 MBps) - https://www.quora.com/From-what-maximum-speed-can-a-smartphone-download-or-upload-some-data
- Ask DAU. If MAU is provided, atleast ask % of concurrent users. 
- Ask user activity : example read vs write ratio, or number of writes (example, 2 tweets per day)
- Ask non-functional requirements 

  Usually Latency and Scale and most important 

  These are very important and can convert entire inteview in your favor. Example if latency is 1s, then you do not need complex caching architecture if your data transfer is less than 100 MB (100 MBps max bandwidth today)

   
    1. Reliability (Superset of latency -> availability -> consistency -> durability) 
          means you need to meet certain standards. 
          Example - latency, consistency, accuracy, durability - error rate, faults

            Ask specific questions here rather than - ":((sad) how reliable you need the system to be :((sad)" 
              - availability over consistency ? 
              - if high availability, then ask availability nos example, 99.999 or 3 9s
              - if consistency over availability, it means high consitency.
              - if low - medium consistency, you can ask specific questions
              - then, data freshness (example, building search engine or yelp)
                  With this you can even decide that, your system could be out of sync from third part servers for 10s in a day
              - then, durability - error rate or data loss
              - with this in mind, it provides as good reasoning about latency 

            -- Latency 
              this would help decide whether you really need low latency optimizations like cache, or not. 
              Remember today mosts have 1 Gbps network which has 10 us to transfer 1 KB

            -- Availability 
              this would help decide the redundancy and reliability - example mostly 99.99% a day means you can compromise 10s (10 ^ 5 * 10 ^ -4).
              of unavailability (its different from being unrelible). 
              With this you can even decide that, your system/part of the sytem could be offline for 10s in a day for reasons like roll out, stateful servers scaling, upgrading the database or even doing DB sync etc. 
              3 9s -> 1 s
              4 9s -> 100 ms or less than 1s
              6 9s -> 1 ms or very high (no downtime)
              > 6 ps -> in us or super high (no downtime else SLA violated)

    2. Scalability
          means ability to scale the system with traffic/data increase. 
            Needs understand of these factors in order of importance : 
                # of users, latency (covers consistency compromises), data size, error rate  and last resort called "cost".
            Tips : 
            - try to add stateless servers if possible
            - stateful server only for few use cases like socket connections. Make sure you know how to deal with scalability for socket connections.
    
System design interview framework
  https://www.youtube.com/watch?v=i7twT3x5yv8 

QPS estimate
- Read : Write ratio
  DO NOT divided by no. of seconds to get QPS if its explictly mentioned about concurrent users say 10% of DAU. In such cases, QPS = 10% DAU
- 1 day ~ 10^5 s
- 1 month ~ 3 * 10 ^ 6s and further ~ 10 ^ 6s
- 1 week ~ 7 * 10 ^ 5s and further ~ 10 ^ 6s
----- For time constraints, do not hesitate to round off large amounts

How to use non-functional requirements in decison making

  Availability vs Reliablity 
    https://www.pagerduty.com/resources/learn/reliability/ 
    Availability is a measure of the percentage of time that an IT service or component is in an operable state. Example of not meeting availability is Facebook was down in 2021 for about 3-5 hrs
    Reliability, on the other hand, is a measure of the probability that the system will meet defined performance standards in performing its intended function during a specified interval.  Example of not meeting reliability stands is Twitter was hacked in 2019

  Bandwidth (assume to be 1 GBps ~ 100 MBps which means 1 KB = 10us) 
    - can help reason your latency
    - can help reason your replication or multiple servers
    - can help reason your sharding for database (remember internal data center max bandwidth to 25 Gbps ~ 2.5 GBps which means 1 KB = 1us ) https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-network-bandwidth.html 

  Durability  (I even refer as availability + data correctness with techniques like checksum, parity)
    - can help reason how much to replicate. 
        Example, say 99.999999% (six 9's) durability can be achieved assuming failure rate of one server is  0.01% (say 99.99% guarantee for ec2 on aws). This means you need 2 servers atleast which means 1 replica 
          0.0001 ^ 2    = 0.0000001    or  10 ^ -8
          1 - 0.0000001 = 0.9999999 or  8 9s  
          % * 100       = 99.999999%      or  6 9s 
    - can help to reason out if you need checksum for data integrity
    - can help to reason out if you need commit log (WAL) like Cassandra

  Availability
    - can help reason how much to replicate. See above since minimum availability aws server can offer is 99.9% (https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/appendix-a-designed-for-availability-for-select-aws-services.html). This means you need extra servers if more than one 9.
    with 1 aws server : 99.9%
    with 2 aws server : 99.9999%
          0.001 ^ 2    = 0.000001         or  10 ^ -6
          1 - 0.000001 = 0.999999         or  6 9s  
          % * 100       = 99.999999%        or  4 9s 
    - can help reason for latency
        more availability -> more bandwidth split -> less latency 

  Consistency
    - can help reason for high latency 
    - can help reason for low replication
    - can help reason for MySQL if combined with ACID


Back of envelope questions : 
  1. calculate qps (round this number).  
      Why ? 
        - help in estimating bandwidth and reasons out the need for distributed system
        - helps in estimating storage requirements
  2. if latency requirement is present, calculate api payload rough estimate say 1 KB for 100K QPS ~ 100 MBps
      Why ? 
        - helps in estimating # of servers needed 
  3. calculate storage estimate 
      Why ? 
     - to help decide if sharding is need or master-replica model. Example more than 64 TB of storage definitely needs sharding (most AWS DBs or even cache like Redis has max 64 - 128 TB of storage https://aws.amazon.com/about-aws/whats-new/2020/09/amazon-aurora-increases-maximum-storage-size-128tb/ )





Distributed Systems estimate

    Latency video
      https://www.youtube.com/watch?v=FqR5vESuKe0
      https://bytebytego.com/courses/system-design-interview/back-of-the-envelope-estimation
      https://matthewdbill.medium.com/back-of-envelope-calculations-cheat-sheet-d6758d276b05 

    Estimates in KB

    Send 1 KB sequential from 1 Gbps network = 10 us  
    Send 1 KB sequential from memory  = 0.25 us   (4 GB/s = 0.25 *  10 ^ -6 s) 
    Send 1 KB sequential from SSD   = 1 us    (1 GB/s = 1 * 10 ^ -6 s )
    Send 1 KB sequential from disk    = 30 us     (30 MB/s = 0.03 * 10 ^ -3 s ) 


    L1/L2 cache = 1 ns
    L3 shared cache = 10 ns
    Memory call = 100 ns
    Mutex lock/unlock =	100 ns
    System call = 1 us
    Context switching between linux threads : 10 us
    Ngnix to process http request : 100 us
    SSD write latency : 500 us
    SSD read latency = 16 us
    Round trip within the same datacenter 	 = 500 us 
    Redis cache latency including network : 1 ms (usually 500 us by internal redis)
    Between two availability zones : 5 ms
    Send packet CA (California) ->Netherlands->CA	= 150 ms 
    Disk seek	= 10 ms
    DNS response time ranges : 10ms to 200ms.
    Replication lag guarantee for AWS RDS : < 100 ms 
      https://www.bluematador.com/docs/troubleshooting/rds-replica-lag#:~:text=Replication%20lag%20measures%20how%20far,than%20100ms%20of%20replication%20lag. 
    TLS handshake time : 250 - 500 ms 
        https://zoompf.com/blog/2014/12/optimizing-tls-handshake/#:~:text=This%20handshake%20will%20typically%20take,is%20when%20the%20handshake%20happens. 
        So suggest to use nginx for keep alive and caching session key to avoid SSL/TLS handshake
    Multi-region failover time for AWS RDS : 60-100s  
      https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZSingleStandby.html

    AWS availability ~ 99.9% https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/appendix-a-designed-for-availability-for-select-aws-services.html
    AWS A100 GPU Lambda ~ 1$ per hour https://lambdalabs.com/service/gpu-cloud 
    Max socket connections : 65,536 https://www.ibm.com/docs/en/zos/2.1.0?topic=domain-maximum-number-sockets 
    Max connections on the server : 
        https://josephmate.github.io/2022-04-14-max-connections
        Some think the limit 216=65,536 because that’s all the ports available in the TCP spec.
        Then theoretical limit a server can support on a single port is 2^48 which is about 1 quadrillion. This is huge and not possible.
        So basically, your # of connections depends on CPU, Mem, Network and other resources on the server.
        So to estimate max connections, use request size to memory mapping. Example, At 1M concurrent users, assuming each user connection needs 10KB of memory on the server (this is a very rough figure and very dependent on the language choice - 256 KB for java), it only needs about 10GB of memory to hold all the connections on one box.
        Best idea is to load test your services 
          AWS distributed load tests - https://aws.amazon.com/solutions/implementations/distributed-load-testing-on-aws/ 
            uses containers
            runs on fargate
            supports jmeter scripts


    Modern fiber optic cable vs ethernet (copper) cable
      - 10 Gbps vs 1 Gbps
      - https://www.cablewholesale.com/blog/index.php/2020/09/16/fiber-optic-vs-copper-ethernet-cables-the-difference/#:~:text=A%20more%20modern%20take%20on,much%20faster%20than%20copper%20cables.

  Types of Memory
  https://www.youtube.com/watch?v=lX4CrbXMsNQ
  RAM
  ROM 
  Hard drive
  SSD
  NVMe - high performance interface for SSDs thats connects to CPU via PCIe

  Types of Cache
  https://www.youtube.com/watch?v=dGAgxozNWFE

    HW cache : 
      L1 > L2 > L3
      Virtual memory - 
        maps program address to RAM address  https://www.youtube.com/watch?v=qlH4-oHnBb8
        is equal to RAM + Disk size
      TLB cache for mapping above -  virtual to physical memory address
      OS level 
        Page cache  - recently used disks blocks in memory
        File cache  - 
        iNode cache - speed up file system operations by reducing disk access

    Front-end :
      Browser 
        cache http responses with cache expiration policy
    Back-end : 
      CDN
        improve delivery of static content by caching it from the origin server
        https://cloud.google.com/cdn/pricing 
        remember CDN charges for egress (0.02$ per GiB), cache fill (same charge - 0.01$ per GiB) and 0.0075 per 10K req
      Load balancer cache
        to reduce the load on back-end servers and also improve response time.
      Messaging cache such as Kafka
        caches on disk using sequential IO (pretty fast)
        allows consumer to consume at their own pace
      Distributed caches
        Redis : in-memory db
        RocksDB : LSM tree to leverage disk 
      Full text search
        Elastic search - does reverse indexing which indexes texts to doc id
      Database cache
        WAL : data is first written to WAL before being indexed in B tree
        Buffer pool : cache query results
        Materialized views : precompute query results
        replication log : tracks replication state
          What is replication log
          https://help.serena.com/doc_center/cm/ver14_2_0_1/admin_console/adminhelp/ddevg_replication_logs/what_is_a_replication_log.htm



=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================


Distributed best practices

  Smallest short length required ( say for tiny url )
    The hashValue consists of characters from [0-9, a-z, A-Z], containing 10 + 26 + 26 = 62 possible characters. To figure out the length of hashValue, find the smallest n such that 62^n ≥ 365 billion. 

  Choices with protocol
    - TCP vs UDP
        https://www.spiceworks.com/tech/networking/articles/tcp-vs-udp/
        1. TCP is connection-oriented so you can get an ack (like success 200 OK in HTTP over TCP) while UDP is connectionless
        So UDP protocol is NOT suitable for sending electronic mail, viewing a web page, or downloading a file. However, it is preferred mainly for real-time applications like broadcasting or multitasking network traffic.

        Then why TCP is a still good choice on reciever of live streaming protocols like HLS, DASH ? 
          - because TCP has flow control mechanism to calibrate the pace of data transmission. Depending on the recipient host, TCP can adjust the speed at which data packets travel and avoid overwhelming the recipient. 

        Then what are the scenarios where UDP is recommended ? 
          Video calling (app like Zoom): UDP can support video 30 frames per second refresh rates (frame is single image in the video - https://darvideo.tv/dictionary/frame/ and min is 24 fps and max is 60 fps even better). The data transmission is so fast that a few dropped packets do not affect the user experience. 
          Online gaming: TCP’s many checklists and balances will significantly impact gaming experiences. Without perfect network conditions, frames will frequently freeze, and connections will restart if using TCP. That is why UDP is recommended. 

  Failure detection algo 
    - gossip prototocol to detect availability failures in distributed systems
    - Raft (description below) using used for master-replica model
      

  Master election concensus algo
      Ensure all replicas are always in-sync and master->slave is elected correctly when master goes down. We could use consensus algorithms such as Paxos [21] and Raft [22], or use consensus-based distributed databases such as YugabyteDB [23] or CockroachDB [24].
          https://bytebytego.com/courses/system-design-interview/stock-exchange 
          The leader sends heartbeat messages (AppendEnties with no content as shown in Figure 21) to its followers. If a follower has not received heartbeat messages for a period of time, it triggers an election timeout that initiates a new election. The first follower that reaches election timeout becomes a candidate, and it asks the rest of the followers to vote (RequestVote). If the first follower receives a majority of votes, it becomes the new leader.
      Nice visual - https://raft.github.io/
      Raft is one of the best concensus algo since it also helps in ensuring strong consistency for distributed transaction in cockroachDB https://github.com/cockroachdb/cockroach/blob/master/docs/design.md
      Even when new node is lagging behind or came live, leader in raft sends replication log along with the heartbeat to keep it consistent http://thesecretlivesofdata.com/raft/#replication 
        What is replication log
          https://help.serena.com/doc_center/cm/ver14_2_0_1/admin_console/adminhelp/ddevg_replication_logs/what_is_a_replication_log.htm


  Failure handling algo
  - for temporary failures
      1. Sloppy quorum
        
  - detecting inconsistency          
      1. Merklee tree (can detect and handle failures by syncing remaining replicas)
          What if a replica is permanently unavailable? To handle such a situation, we implement an anti-entropy protocol to keep replicas in sync. Anti-entropy involves comparing each piece of data on replicas and updating each replica to the newest version. A Merkle tree is used for inconsistency detection and minimizing the amount of data transferred.
          Quoted from Wikipedia [7]: “A hash tree or Merkle tree is a tree in which every non-leaf node is labeled with the hash of the labels or values (in case of leaves) of its child nodes. Hash trees allow efficient and secure verification of the contents of large data structures”.
                Step 1: Divide key space into buckets (4 in our example) as shown in Figure 13. A bucket is used as the root level node to maintain a limited depth of the tree.
                Step 2: Once the buckets are created, hash each key in a bucket using a uniform hashing method (Figure 14).
                Step 3: Create a single hash node per bucket (Figure 15).
                Step 4: Build the tree upwards till root by calculating hashes of children (Figure 16).
          https://bytebytego.com/courses/system-design-interview/design-a-key-value-store

  Directed acyclic graph (DAG) model
        To support different video processing pipelines and maintain high parallelism, it is important to add some level of abstraction and let client programmers define what tasks to execute. For example, Facebook’s streaming video engine uses a directed acyclic graph (DAG) programming model, which defines tasks in stages so they can be executed sequentially or parallelly [8]. In our design, we adopt a similar DAG model to achieve flexibility and parallelism. Figure 8 represents a DAG for video transcoding.


  Symmetric vs Asymmetric encryption
    https://blog.mailfence.com/symmetric-vs-asymmetric-encryption/ 
    RSA is asymmetric
    Rest everything is symmetric
    SHA-1 is hash function and not encryption one
    SHA-256 is more secure https://www.keycdn.com/support/sha1-vs-sha256 

  Eliminate disk access
    Disk accesses can be eliminated using mmap. `mmap(2)` provides a mechanism for high-performance sharing of memory between processes. 
    Modern exchanges take advantage of this to eliminate as much disk access from the critical path as possible. `mmap(2)` is used in the server to implement a message bus over which the components on the critical path communicate. The communication pathway has no network or disk access, and sending a message on this mmap message bus takes sub-microsecond. By leveraging mmap to build an event store, coupled with the event sourcing design paradigm which we will discuss next, modern exchanges can build low-latency microservices inside a server.

  Change Data Capture
  CDC is a mechanism that reads data changes from the database and applies the changes to another data system. One common solution is Debezium [9]. It uses a source connector to read changes from a database and applies them to cache solutions such as Redis [10].

  In-sync replicas
    https://bytebytego.com/courses/system-design-interview/distributed-message-queue
    We mentioned that messages are persisted in multiple partitions to avoid single node failure, and each partition has multiple replicas. Messages are only written to the leader, and followers synchronize data from the leader. One problem we need to solve is keeping them in sync.
    In-sync replicas (ISR) refer to replicas that are “in-sync” with the leader. The definition of “in-sync” depends on the topic configuration. For example, if the value of replica.lag.max.messages is 4, it means that as long as the follower is behind the leader by no more than 3 messages, it will not be removed from ISR [10]. The leader is an ISR by default.

  Data mirroring with replicas
    https://bytebytego.com/courses/system-design-interview/distributed-message-queue 
    If all the replicas of a partition crash, the data for that partition is lost forever. When choosing the number of replicas and replica locations, there’s a trade-off between data safety, resource cost, and latency. It is safer to distribute replicas across data centers, but this will incur much more latency and cost, to synchronize data between replicas. As a workaround, data mirroring can help to copy data across data centers, but this is out of scope. The reference material [14] covers this topic.
    Mirroring refers to keeping a backup database server for a master database server. It is not meant for distributed systems like (master(write)->replica(read)) and serves as a DR result. So this is reason why there is always mirroring on replicas
    https://www.tutorialspoint.com/difference-between-mirroring-and-replication 

  HTTP Encrpytion, Authentication, Authorization and Security 
        Asymmetric encryption could be used here for payment gateway
          https://www.youtube.com/watch?v=AQDCe585Lnc
          also used in HTTPS, SSH, Bitcoin, Emails using PGP protocol

        How HTTPS works ? How it uses SSL and TLS
          https://www.youtube.com/watch?v=hExRDVZHhig
          HTTPS uses public key encryption to secure data using SSL (Secure socket layer) protocol. Basically server gives SSL certicate to client and acknowledgement is established between the two. Then info can be transferred securely using encryption.
          TLS is latest and successor of SSL
          Today most websites supports https because of google standards

          ByteByteGo : https://www.youtube.com/watch?v=j9QmMEWmcfo
            Moderm HTTPS uses TLS
            1. first establishes TCP handshake at transport 
            2. then client sends hello and gets the certificate from server which has public key of server (Asymmetric) 
            3. then client encryptes his/her session key with server's public key and then on server, it gets clients sesssion key by decrypting with server's private key. This is Asymmetric encryption
            4. Now both has session key and uses session key as cipher to encrypt and decrypt at both sides. This is Symmetric encryption.

            SSL uses public key encryption (Asymmetric encryption) only. However, this website claims it supports both Asymmetric and symmetric - https://www.trentonsystems.com/blog/symmetric-vs-asymmetric-encryption
          

        TLS handshake latency 
          TLS handshake time : 250 - 500 ms https://zoompf.com/blog/2014/12/optimizing-tls-handshake/#:~:text=This%20handshake%20will%20typically%20take,is%20when%20the%20handshake%20happens.  
          Suggestion is to use nginx which uses keep-alive and stores encrypted session key 

          How SSO work ? 
            https://www.youtube.com/watch?v=O1cRJWYF-g4
            
            Two ways 
              using SAML
                - uses XML 
                - uses public key encryption 
              Open id connect
                - uses json web token (JWT) 
                - which uses token

        Authentication and Authorization
          https://blog.bytebytego.com/p/password-session-cookie-token-jwt 
          modern websites uses session id
          
          Oauth 2.0 work ? 
            https://www.youtube.com/watch?v=CPbvxxslDTU
            JWT is data format for user information in the OpenID Connect standard, which is the standard identity layer on top of the OAuth 2.0 protocol. Nginx plus supports this - https://docs.nginx.com/nginx/admin-guide/security-controls/configuring-jwt-authentication

            Related to above 
            How payment gateway work ?
              https://www.youtube.com/watch?v=GUurzvS3DlY

        Session id based authenitication vs JWT
          https://stytch.com/blog/jwts-vs-sessions-which-is-right-for-you/ 
          - session id needs db look up after authentication although nginx can cache it
          - jwt does not need db look up since all necessary info is contained in the client request. Invalidating JWT token is complex so token is valid even after log out.

  Network/s / Networking
    OSI model
      https://www.youtube.com/watch?v=0y6FtKsg6J4

    HTTP over TCP/IP 
      https://www.goanywhere.com/blog/http-vs-tcp-whats-the-difference
      In the case of HTTP which applies at layer 7, before a client and server can exchange an HTTP request/response, they must establish a TCP connection first. Therefore, HTTP relies on the TCP standard in order to successfully do its job.

      HTTP 1.0, 1.1 and 2.0
        https://www.youtube.com/watch?v=a-sBfyiXysI
        1.0 -> 
          tcp handshake all the time. Very low performat
        1.1 -> 
          keep alive, persistent conenection avoids tcp handshake. But suffers from head of line blocking - if a request is blocked for any reason them all subsequent requests are blocked. So applications like browsers send muliple requests by opening many TCP connections in parallel.
        2.0 -> 
          brought concept of multiple independent streams on same tcp connection which resolves head of line blocking at application layer. But the issue still in transport layer in TCP.
          it brought push capabiliy (SSE) to send update to the client from  the server
        3.0 -> Quic which uses UDP
          recent and used Quic protocol which uses UDP instead of TCP
          multiple streams share the same Quic connection. Due to use of UDP, it resolves head of line blocking even at transport layer
          Application : 
            designed for mobile heavy internet usage where user keeps connecting between different networks.
            How ? uses the concept of connection id between client and server which always remains same even if different network is selected. 

        https://www.linkedin.com/posts/gkcs_http3-systemdesign-networkprotocols-activity-7041095963335139329-uV44/?utm_source=share&utm_medium=member_desktop 

    Video streaming protocol
      https://linuxhit.com/rtmp-vs-hls-vs-dash-streaming-protocols/#0-rtmp-vs-hls-vs-dash-streaming-protocols 
      RTMP
        RTMP stands for Real Time Messaging Protocol. Sounds more generic than streaming doesn’t it? RTMP is a creation of Macromedia and through Adobe’s acquisition of Macromedia it now belongs to Adobe. Remember all those flash videos and the flash player?
        RTMP is a TCP based protocol designed for low latency.
        Low latency vs HLS and DASH.
        Used heavily in production or broadcasting of video streams from streamer's device
      HLS
        HLS is Apple’s streaming protocol. HLS stands for HTTP Live Streaming. Leveraging HTTP has many benefits. Internet infrastructure like firewalls and content delivery networks already handle HTTP.
        - key benefit of HLS is adaptive streaming. Adaptive streaming enables changing the quality of the video mid-stream. For example, if your internet connection starts slowing down, the bit rate can adapt to ensure the stream stays viewable. Despite the degradation in bandwidth.
        - HLS only supports the H264 codec for video and AAC for audio.
      DASH
        DASH stands for Dynamic Adaptive Streaming is an open standard and similar to HLS. It uses HTTP, small chunks and also supports adaptive streaming. A key difference between HLS and DASH is that DASH is codec agnostic. Hence you can use any codec you want.

    DNS
      https://www.youtube.com/watch?v=27r4Bzuj5NQ
      queries from browser go to DNS resolver (ISP, Cloudfare, Google) which fetches authoritative name server in hierarchial fashion.
      DNS lookups are cached at client machine, resolver

    How Wifi works
      https://computer.howstuffworks.com/wireless-network.htm
      A wireless network uses radio waves, just like cell phones, televisions and radios do.
        1. A computer's wireless adapter translates data into a radio signal and transmits it using an antenna.
        2. A wireless router receives the signal and decodes it. The router sends the information to the internet using a physical, wired ethernet connection.
      The radios used for WiFi communication are very similar to the radios used for walkie-talkies, cell phones and other devices. They can transmit and receive radio waves, and they can convert 1s and 0s into radio waves and convert the radio waves back into 1s and 0s.
      2.4 GHz connections are now considered somewhat obsolete because they carry lower data speeds than 5 GHz.
      Remember 2.4 GHz vs 5 GHz this is different from 4G vs modern 5G (upto 1Gbps) which is based on bandwidth to tranfer data

    Anycast 
      https://www.youtube.com/watch?v=vOYjcOs1dUU
      multiple servers with same IP address so that nearest one can serve. Example, CDN

  API design for websocket connection
    https://bytebytego.com/courses/system-design-interview/nearby-friends
    - do not add paths else it will look like REST which is HTTP
    format
      1. Initiated by Client : Request and Response
      2. Initiated by Server : Data sent 

  Physical cores, Virtual cores and Logical cores
    https://www.youtube.com/watch?v=O2g6381An_k 

  Processes vs Thread
    https://www.youtube.com/watch?v=4rLW7zg21gI 
      Process is responsible for executing set of instructions from an application
      Process will contain multiple threads


  Logging (errors), Metrics Monitoring (system level, business) and automated Deployment
    Logging (errors)
      - datadog
      - logging errors to trigger alerts, sev
    Metrics Monitoring (system level, business)
      - datadog, 
    Alerting
      - datadog
    Continuous integration
        develop -> commit -> build -> test ->  deploy
      https://blog.inedo.com/continuous-integration-performance-testing-best-practices

  Failure/Error handling
    Common techniques are retry the processing for queue consumer or offload to another server 
    try maintaining the commit log
    explore event sourcing technique

  Verify integrity through blockchain
    https://www.youtube.com/watch?v=SSo_EIwHSd4 


  Event sourcing
      https://www.confluent.io/blog/event-sourcing-cqrs-stream-processing-apache-kafka-whats-connection/
      https://bytebytego.com/courses/system-design-interview/digital-wallet
    One design philosophy that systematically answers those questions is event sourcing, which is a technique developed in Domain-Driven Design (DDD) [9].

  Using LSMTree + SSTable are efficienct for heavy writes and heavy reads on noSQL databases. B tree is not
      Great video : https://www.youtube.com/watch?v=I6jB0nM9SKU 
      Good read : https://rahulpradeep.medium.com/sstables-and-lsm-trees-5ba6c5529325
      This technique is used by Cassandra, RocksDB, Google BigTable, Apache HBase
      MongoDB can be tuned to use LSM treee
    
  Algo if element is the member of the set
    Use Bloom filter
      https://www.youtube.com/watch?v=V3pzxngeLqw
      A bloom filter is a space-efficient probabilistic technique to test if an element is a member of a set. Refer to the reference material [2] for more details.
      Applications
        key value store to check in SSTable
        crawlers to check if url in malicious 
        CDN if page is in cache
  
  Clock synchronization amongst different servers in distributed systems
    https://www.youtube.com/watch?v=f1hlCZB0GDA 
    - Use network time protocol 

  Dynamic rendering to allow search engines to parse content
    https://developers.google.com/search/docs/crawling-indexing/javascript/dynamic-rendering 
    Dynamic rendering is a workaround and not a recommended solution, because it creates additional complexities and resource requirements.

  Scale through Kafka
    Kafka is known for high throughput, low latency streaming, message persistence, high availability, fault tolerant system
    https://bytebytego.com/courses/system-design-interview/metrics-monitoring-and-alerting-system
    There are a couple of ways that we can leverage Kafka’s built-in partition mechanism to scale our system.
      Configure the number of partitions based on throughput requirements.
      Partition metrics data by metric names, so consumers can aggregate data by metrics names.
      Further partition metrics data with tags/labels.
      Categorize and prioritize metrics so that important metrics can be processed first - possible with kafa

  Scale map reduce operations 
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation 
    If you are interested in the details, please refer to reference material [20]. Aggregation service is horizontally scalable by adding or removing nodes.
    Question is how you increase the throughput ? 
        1. assign each thread in the server
        2. deploy aggregation service nodes on resource providers like Apache Hadoop YARN [21]
      Option 1 is easier to implement and doesn’t depend on resource providers. In reality, however, option 2 is more widely used because we can scale the system by adding more computing resources.
  Using star schema as pre-filtered form 
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation
    To support data filtering like “show me the aggregated click count for ad001 within the USA only”, we can pre-define filtering criteria and aggregate based on them. This technique is called the star schema [11], which is widely used in data warehouses. The filtering fields are called dimensions. 
    A limitation with this approach is that it creates many more buckets and records, especially when we have a lot of filtering criteria.


  Combine batch processing and streaming with one service 
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation
    For a system that contains two processing paths (batch and streaming) simultaneously, this architecture is called lambda [14]. A disadvantage of lambda architecture is that you have two processing paths, meaning there are two codebases to maintain. Kappa architecture [15], which combines the batch and streaming in one processing path, solves the problem. The key idea is to handle both real-time data processing and continuous data reprocessing using a single stream processing engine. 

  Process delayed events 
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation
    One way to mitigate this problem is to use “watermark” (the extended rectangles in Figure 14), which is regarded as an extension of an aggregation window. This improves the accuracy of the aggregation result. By extending an extra 15-second (adjustable) aggregation window, window 1 is able to include event 2, and window 3 is able to include event 5.

  Aggregation window
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation
    According to the “Designing data-intensive applications” book by Martin Kleppmann [16], there are four types of window functions: tumbling (also called fixed) window, hopping window, sliding window, and session window. We will discuss the tumbling window and sliding window as they are most relevant to our system.

  Fault tolerance systems
    - retry logic by storing last online state in S3 / KV store
    - save computational work in snapshots storage for low latency (https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation)

  Monitoring metrics
    total Latency and also at each stage
    Queue size if used
    system resources : CPU, disk, JVM, etc.

  Reconcilliation for data consistency
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation
    Reconciliation means comparing different sets of data in order to ensure data integrity. Unlike reconciliation in the banking industry, where you can compare your records with the bank’s records, the result of ad click aggregation has no third-party result to reconcile with.

  Alternative designs for aggregation
    https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation 
    In a generalist system design interview, you are not expected to know the internals of different pieces of specialized software used in a big data pipeline. Explaining your thought process and discussing trade-offs is very important, which is why we propose a generic solution. Another option is to store ad click data in Hive, with an ElasticSearch layer built for faster queries. Aggregation is usually done in OLAP databases such as ClickHouse [24] or Druid [25]. Figure 29 shows the architecture.


  Line protocol
    https://bytebytego.com/courses/system-design-interview/metrics-monitoring-and-alerting-system
      CPU.load host=webserver01,region=us-west 1613707265 76
      CPU.load host=webserver01,region=us-west 1613707265 83

      The average CPU load could be computed by averaging the values at the end of each line. The format of the lines in the above example is called the line protocol. It is a common input format for many monitoring software in the market. Prometheus [6] and OpenTSDB [7] are two examples.

          A metric name	String
          A set of tags/labels	List of <key:value> pairs
          An array of values and their timestamps	An array of <value, timestamp> pairs

  Push vs Pull model
      https://bytebytego.com/courses/system-design-interview/metrics-monitoring-and-alerting-system 
      Metrics monitoring : 
        Examples of pull architectures include Prometheus.
        Examples of push architectures include Amazon CloudWatch [16] and Graphite [17].

      Easy debugging: pull
      Health check : pull
      Short lived jobs : push
          Some of the batch jobs might be short-lived and don’t last long enough to be pulled. Push wins. But This can be fixed by introducing push gateways for the pull model [22].
      Firewall or complicated network setups : push
      Performance : Push
        since push uses UDP, it wins vs pull which relies on TCP
      Data authenticity	: Pull
        zookeeper can provide valid servers to pull from
      Fault tolerant and reliability : Pull
        since failed messages can be queried again

  gRPC
    For production systems, inter-service communication often employs a modern and high-performance remote procedure call (RPC) framework like gPRC. There are many benefits to using such frameworks. To learn more about gPRC in particular, check out [3].

  Avoid Risk of double booking in transaction systems like hotel rooms, payment systems
    There are two common approaches to solve this problem:

      Client-side implementation. A client can gray out, hide or disable the “submit” button once a request is sent. This should prevent the double-clicking issue most of the time. However, this approach is not very reliable. For example, users can disable JavaScript, thereby bypassing the client check.

      Idempotent APIs. Add an idempotency key in the reservation API request. An API call is idempotent if it produces the same result no matter how many times it is called. Figure 8 shows how to use the idempotency key (reservation_id) to avoid the double-reservation issue. The detailed steps are explained below.

  Different types to avoid race conditions during concurrency
  applications : hotel booking for last room, uber drivers all responding to request
    1. Pessimistic locking 
        - as name suggests, it locks the record while read + update
        - good when data contention is high
        - slows down performance
    2. Optimistic locking
        - has validation check based on version number. So no locking is needed. 
        - good when data contention is low and improves performances
        - bad when data contention is high 
    3. database constraint
        - add constraint at table level
        - same as Optimistic and its easier to implement

  CI/CD practices
    https://www.youtube.com/watch?v=42UP1fxi2SY
    - CI stands for continuous integration and is more common. Its the practice of using automation to enable teams to merge code changes in shared repository. Each commit triggers an automated workflow on the CI server that builds and runs series of tests to make sure commit is safe to merge into main branch.
      - CI process : code -> build -> test -> release
      - tools for CI - github
      - tools to manage CI process: code (github), build (gradle, webpack, github actions), test (jest), release (jenkins, buildkite)

    - CD stands for continuous deployment but it is hard and many companies only apply to stateless systems. Needs good production monitoring for CD like datadog. Blue green deployments is common. Canary deployment is also possible for products with 100 million users.
    - CD is hard for database backend clusters or websocket cluster. So deployment process is manual here and needs dedicated platform team
      - CD process : code -> build -> test -> acceptance -> deploy in production
      - CD tools : github actions, jenkins, argoCD for kubernetes 

  How to provison resources in the could
    https://www.youtube.com/watch?v=tomUWcQ0P3k
    Use terraform as Infrastructure as code

  
  How to store password in the database
    https://www.youtube.com/watch?v=zt8Cocdy15c
    use hashing + salt

  Bare metal, VMs and containers
    https://www.youtube.com/watch?v=Jz8Gs4UHTO8
    VMs have hypervisor to run the guest OSes
    Containers have container agent (eg., docker) instead of hypervisor to run the application in its own environment but uses instance/host OS to operate and have faster operations and more flexibility but suffers from security sharing common instance/host OS. To achieve security, you can have a container inside the VM but it looses flexibility now. 

  Cloud Native practices
    https://www.youtube.com/watch?v=p-88GN1WVs8
    - microservice architecture
    - containers
    - Dev ops (ci/cd)
    - Cloud native open standards (distributed tracing, service mesh)

  Kubernetes
    https://www.youtube.com/watch?v=TlHvYWVUZyc
    - container orchestration system
    - use it when you need self-healing (downtime), horizontal scaling and automated rollbacks (deployment)
    - due to its complexity, do not use it if your org is small enough
    https://www.youtube.com/watch?v=VnvRFRk_51k&t=78s
      use master-worker architecture. 
        Master - 
          - contains API server which can accept configuration about your application through YAML file
          - controller managers to keep track of what's happening in the cluster
          - scheduler ensures pod placement on workers
          - etcd which has info about workers and also a backing store 
          - has another master as secondary to avoid SPOF 
        Workers 
          - deploys your application into pods which is a wrapper for containers. So one pod can have many containers.
          - usually its one pod per application. You only have multiple applications in one pod when its helper to another - example, docker agent.
          - If pod dies, new ones gets easily created.
          - Since each pod gets IP address, then won't it creates disruption if a pod dies. Example MySQL pod dies ? 
            - So pod is supported by "service" (may be kube-proxy) sitting in each pod concept which is similar to load balancer and IP address is assigned to a service instead of a pod. It also serves as a load balancer
          Similar video : https://www.youtube.com/watch?v=2vMEQ5zs1ko 

  WebSocket - use for bi-directional communication
    Websocket with load balancer or not - debatable 
      websocket can be supported with load balancing through websocket tunned but suggest not to do it https://www.haproxy.com/documentation/hapee/latest/load-balancing/protocols/websocket/ 
      comparison of websocket vs long polling during scaling up / down  
        - https://dev.to/kevburnsjr/websockets-vs-long-polling-3a0o 
      Some systems does support websocket and load balancer https://bytebytego.com/courses/system-design-interview/nearby-friends 
    Types of socket connections
      https://www.ibm.com/docs/en/zos/2.1.0?topic=sockets-socket-types
      Stream - data transmitted in continuous stream with length so that the receiver can read that length and process the data. Its reliable means data is sent without error or duplication
      Datagram -  socket interface defines a connectionless service. Datagrams are sent as independent packets. The service provides no guarantees; data can be lost or duplicated, and datagrams can arrive out of order
      raw socket -  interface allows direct access to lower layer protocols, such as IP and Internet Control Message Protocol (ICMP). This interface is often used for testing new protocol implementations.
    Websocket API
      https://www.geeksforgeeks.org/difference-between-rest-api-and-web-socket-api/ 
      - Unlike REST, Websocket API does not require a new connection to be set up for each message to be sent between clients and servers. Once the connection is set up the messages can be sent and received continuously without any interruption.
      - WebSocket APIs are suitable for IoT Applications with low latency or high throughput requirements. 
      - Websockets could be scaled on single server ~ 65K ports
      - Challenges with websocket are security, browser compactibility and complex to handle
    Difference between socket and a port
      https://www.geeksforgeeks.org/difference-between-socket-and-port/?ref=rp
      Both Socket and Port are the terms used in Transport Layer. A port is a logical construct assigned to network processes so that they can be identified within the system. A socket is a combination of port and IP address. An incoming packet has a port number which is used to identify the process that needs to consume the packet.

    IOT devices
      https://www.youtube.com/watch?v=6mBO2vqLv38
      - all devices are connected to IOT gateway through MQTT or HTTP
      IOT device architecture
        https://www.youtube.com/watch?v=KeaeuUcw02Q&t=630s
        - IoT devices (sensors)
        - IoT Gateway (collect data from sensors)
        - Cloud (Processing engine or event processing layer)
        - Application layer or API management layer 
        entire layers above is secured by device manager and IAM
      IoT Reference architecture
        https://www.youtube.com/watch?v=KeaeuUcw02Q&t=630s
        - Device layer
          like sensors which are interconnected 
          eg., bluetooth (via mobile phone -> Wifi gateway), raspberry pi (via Wifi -> direct connect to ethernet), zigbee (via zigbee gateway)
        - Communication layer or Gateway layer
          Rest protocol - HTTP or MQTT
        - Bus layer or Aggregation layer
          acts as a message broker supports http server or MQTT broker or Gateway
        - Even processing and Analysics layer (cloud)
      How IoT devices connect to the internet
        https://theiotpad.com/different-ways-to-connect-iot-device-over-internet/
        Communication devices include Wi-Fi, Bluetooth, and Ethernet cables.
        Although Wi-Fis use more power than your average Bluetooth system, they are more reliable and scalable. You can receive signals to your mobile devices and relay signals that penetrate barriers like walls and objects.

      Practical 
        https://www.youtube.com/watch?v=QyIeFy2-MvU
        light bulb having an IP address connected via a computer application using node.js



 
  Use Nginx 
    - Has triats of load balancing + reverse proxy + API gateway
         - supports load balancing
         - supports request forwarding based on different paths like api gateway
         - supports reverse proxy 
         - supports rate limiting
         - supports caching
         - supports request grouping
         - supports secure auth SSL. Also does optimizations with keep alive connection and cache to avoid SSL handshake - https://docs.nginx.com/nginx/admin-guide/security-controls/terminating-ssl-http/ 
         Also a good read https://www.nginx.com/blog/http-keepalives-and-web-performance/
    - Nginx supports L7 (application level load balancer) and also L4 ? 
    - For modern websites, Nginx in form of reverse proxy is set up at multiple layers 
        - first layer : edge server 
        - second layer : API gateway / load balancer
        However, many of them combine both as one ingress service

  Use gRPC as interservice communication between microservices in your cloud
  https://www.youtube.com/watch?v=gnchfOojMk4
    - its high performant because 
          -it uses protocal buffers as efficiency binary encoding format as compared to json and 
          - http 2.0
    - supports many programming languages

  Multipart upload when upload file or video
    https://bytebytego.com/courses/system-design-interview/s3-like-object-storage 
    It is possible to upload such a large object file directly, but it could take a long time. If the network connection fails in the middle of the upload, we have to start over. A better solution is to slice a large object into smaller parts and upload them independently. After all the parts are uploaded, the object store re-assembles the object from the parts. This process is called multipart upload.

    - S3 client supports multipart upload (https://www.baeldung.com/aws-s3-multipart-upload)
    - S3 also supports faster multipart upload through edge locations called "transfer acceleration" https://aws.amazon.com/blogs/compute/uploading-large-objects-to-amazon-s3-using-multipart-upload-and-transfer-acceleration/  
    - HTML support "multipart/form-data" encoding type which is used for forms that include binary data, such as an image or audio files. When a user submits a form with “multipart/form-data” encoding, the data is split into multiple parts and sent to the server in a way that preserves the binary data. The data is then reassembled by the server and processed accordingly.
    - you can parallelize video upload with GOP alignment (https://bytebytego.com/courses/system-design-interview/design-youtube)
    - For email attachment
      An email attachment is sent along with an email message, commonly with Base64 encoding [6]. There is usually a size limit for an email attachment. For example, Outlook and Gmail limit the size of attachments to 20MB and 25MB respectively as of June 2021. This number is highly configurable and varies from individual to corporate accounts. 
      Multipurpose Internet Mail Extension (MIME) [7] is a specification that allows the attachment to be sent over the internet. https://bytebytego.com/courses/system-design-interview/distributed-email-service

  Use GPU for video transcoding 
    Meta uses GPU as ASICs for AI Inference or video transcoding

  Use Snapshot Isolation to handle dirty read, phantom read and is high performant as compared to serializable (pessimistic locking)
    How snapshot actually works : https://www.youtube.com/watch?v=Tgpa9TrxsfU 
      it just stores all versions of modified rows in WAL and reads from a committed transaction in WAL. So you do not have to worry about someone modify/add the data when you are read (dirty or phantom read) because at transaction x, all rows were in consistent state.
    https://www.geeksforgeeks.org/what-is-snapshot-isolation/
    Dirty read, phantom read
    https://jennyttt.medium.com/dirty-read-non-repeatable-read-and-phantom-read-bd75dd69d03a
    With nice demo - https://techcommunity.microsoft.com/t5/sql-server-blog/serializable-vs-snapshot-isolation-level/ba-p/383281  
    Cockraoch DB uses snapshot isolation - https://github.com/cockroachdb/cockroach/blob/master/docs/design.md 
    
    Issue with Snapshot Isolation : 
     "write skew anamoly" with this approach https://www.youtube.com/watch?v=eym48yrObhY 
      it is possible for an SI-based concurrency control to interleave some transactions, where each transaction preserves an integrity constraint when run alone, but where the final state after the interleaved execution does not satisfy the constraint. This occurs when concurrent transactions modify different items that are related by a constraint, and it is called the “Write Skew” anomaly.


  Use CQRS pattern to improve performance
    https://medium.com/design-microservices-architecture-with-patterns/cqrs-design-pattern-in-microservices-architectures-5d41e359768c# 
    CQRS stands for Command and Query Responsibility Segregation, a pattern that separates read and update operations for a data store. Implementing CQRS in your application can maximize its performance, scalability, and security.

    CQRS will need event sourcing since it will generate sync events from write DBs to read DBs.

    Example CQRS application is digital wallet system design where you need to separate our read and write part - https://bytebytego.com/courses/system-design-interview/digital-wallet



=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================


Distributed systems today and Benchmarking on common systems

    Live streaming
      https://www.youtube.com/watch?v=7AMRfNKwuYo
      - streamer device(encoder) --> PoPs --> transcoding(different resolutions and bitrate) --> packaging (hls, dash format) --> PoPs --> receiving device (decoder)
            1. streamer starts his stream wired up to an encoder (software in browser, webcam, mobile ) which packages the video stream and send it in a transport protocol that the live streaming platform can recieve for further processing.
            2. transcoding is divided into smaller video called segmentations which is then processed in parallel which needs lots of CPU.
            3. then packaged to support most common live streaming format - HLS, DASH (.mp4)

      * Video transcoding is also called video encoding
        Many types of encoding formats are available; however, most of them contain two parts:
          Container: This is like a basket that contains the video file, audio, and metadata. You can tell the container format by the file extension, such as .avi, .mov, or .mp4.

          Codecs: These are compression and decompression algorithms aim to reduce the video size while preserving the video quality. The most used video codecs are H.264, VP9, and HEVC.

      Why RTMP for live streamer and HLS/DASH for receiver/consumer
        https://linuxhit.com/rtmp-vs-hls-vs-dash-streaming-protocols/#0-rtmp-vs-hls-vs-dash-streaming-protocols 
        RTMP vs HLS vs DASH – Which one should I use?
          If you are producing live video content then you probably want to publish your stream to a streaming server via RTMP. It is possible to allow consumption of the stream via RTMP. But you probably don’t want to do that. HLS has widespread support on client devices that consume your video. Additionally you can leverage CDNs and not need to worry about firewalls. So you will want to broadcast with HLS.

      - Protocols
        - the most popular transport protocol is RTMP which is TCP based but moving towards SRT which is UDP based
        - remember hls, dash formats are different from streaming protocol - hls, dash.
        - RTMP is a TCP-based protocol that is widely used because it offers persistent connections and low-latency streaming. On the other hand, HLS is an HTTP-based protocol for adaptive bitrate streaming of live and on-demand content. It is often better than RTMP because it has a lower latency. https://castr.com/blog/rtmp-vs-hls/ 

    Video conferencing app like Zoom
      https://medium.com/@himanishaik48/zoom-system-design-most-frequently-asked-question-in-interview-f60f6fe8d198 
 
    Multiplayer Gaming distributed app
      https://theredrad.medium.com/designing-a-distributed-system-for-an-online-multiplayer-game-requirements-part-2-de1d1ae9ae9b
      - use of kubernetes
      - use of TCP tunnels
      How unity company multiplayer game architecture - https://www.youtube.com/watch?v=77vYKsXC4IE 
        - Amazon GameLift has dedicated server for hosting games
        - GCP also has game server built on top of kubernetes 
        - use auth provider like playfab
        - use matching server like playfab matching or flexmatch from amazon gamelift
        - leaderboard, 
        - persistent data like sql
        - use GameAnalytics

    Design search engine
      https://medium.com/double-pointer/system-design-interview-search-engine-edb66b64fd5e 
        Web -> Crawler -> Indexer -> Retiever <-> Web Browser or Mobile

        Crawler : crawls from robots.txt, uses some seed URLs, uses priority Q, adds links in priority Q to crawl next
        Indexer : pre-process (remove stop words), indexes usually inverted index as word -> doc ids
        Retreiver : 
          Since search query have multiple words, two types : 
            Conjunctive Search which is AND based 
            Disjunctive Search which is OR based

    Types of database indexes
      https://medium.com/must-know-computer-science/system-design-indexes-f6ad3de9925d 


    Layer 4 Load balancer
      https://www.nginx.com/resources/glossary/layer-4-load-balancing/
      When the Layer 4 load balancer receives a request and makes the load balancing decision, it also performs Network Address Translation (NAT) on the request packet, changing the recorded destination IP address from its own to that of the content server it has chosen on the internal network. Similarly, before forwarding server responses to clients, the load balancer changes the source address recorded in the packet header from the server’s IP address to its own. 
      Layer 4 load balancers make their routing decisions based on address information extracted from the first few packets in the TCP stream, and do not inspect packet content.

    Layer 7 Load balancer
      https://www.nginx.com/resources/glossary/layer-4-load-balancing/ 
      Layer 7 load balancers base their routing decisions on various characteristics of the HTTP header and on the actual contents of the message, such as the URL, the type of data (text, video, graphics), or information in a cookie.
      Taking into consideration so many more aspects of the information being transferred can make Layer 7 load balancing more expensive than Layer 4 in terms of time and required computing power, but it can nevertheless lead to greater overall efficiency. For instance, because a Layer 7 load balancer can determine what type of data (video, text, and so on) a client is requesting, you don’t have to duplicate the same data on all of the load-balanced servers.

    
    Map Reduce
      https://www.youtube.com/watch?v=MAJ0aW5g17c (awesome)
        Example of GFS performing map function on worker servers and reduce using worker servers co-ordinated by master
      The MapReduce framework is a good option to aggregate ad click events. The directed acyclic graph (DAG) is a good model for it [9]. The key to the DAG model is to break down the system into small computing units, like the Map/Aggregate/Reduce nodes (https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation). Facebook uses DAG model for its video streaming
      Hotspot issue in map reduce
        supported by resource manager (https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation)

    Zookeeper 
     - centralized configuration, key value store for state and also co-ordination service like selecting leader/master
     - can perform as a shard manager to find out the shard based on key ( https://kousiknath.medium.com/all-things-sharding-techniques-and-real-life-examples-in-nosql-data-storage-systems-3e8beb98830a#:~:text=You%20can%20use%20some%20configuration,directly%20talk%20to%20the%20shard. )
     - The number of partitions and addresses of all Redis nodes can be stored in a centralized place. We could use Zookeeper [4] as a highly-available configuration storage solution. (https://bytebytego.com/courses/system-design-interview/digital-wallet)
     - Apache Zookeeper [7] is a popular open-source solution for service discovery. It registers all the available chat servers and picks the best chat server for a client based on predefined criteria. (https://bytebytego.com/courses/system-design-interview/design-a-chat-system). You can also use this strategy for game server. 
     - There are many service discovery packages available, with etcd [4] and Zookeeper [5] among the most popular ones. Our need for the service discovery component is very basic. https://bytebytego.com/courses/system-design-interview/nearby-friends 
        - Under the “Key” mentioned in point 1, we store a hash ring of all the active Redis pub/sub servers in the service discovery component (See the consistent hashing chapter in Volume 1 of the System Design Interview book or [6] on details of a hash ring). The hash ring is used by the publishers and subscribers of the Redis pub/sub servers to determine the pub/sub server to talk to for each channel. 
      https://ramcloud.atlassian.net/wiki/spaces/RAM/pages/6848719/ZooKeeper+Performance 
      

    Kafka
      https://www.youtube.com/watch?v=UNUz1-msbOM
      latency : 1 ms
      Why fast :
      - sequential access from the disk with append-omly log 
      - zero copy principle ( copy path from disk -> os buffer -> application buffer -> socket buffer -> nic buffer TO  disk -> os buffer  -> socket buffer )
      Excatly once delivery is hard but Yelp implements it. Check it out https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation 
        To achieve “exactly-once” processing, we need to put operations between step 4 to step 6 in one distributed transaction. A distributed transaction is a transaction that works across several nodes. If any of the operations fails, the whole transaction is rolled back.
      Benchmarking
        https://developer.confluent.io/learn/kafka-performance/
        5 ms
        600 MB/s on 25 Gbps network on AWS 
        i3en.2xlarge instance type (with 8 vCores, 64 GB RAM, 2 x 2,500 GB NVMe SSDs)

    RabbitMQ
      https://www.upsolver.com/blog/kafka-versus-rabbitmq-architecture-performance-use-case
      - supports both point to point and pub-sub model.
      - once messages are consumed, the are removed from queue and acknowledgement is provided
      - It can be both synchronous and asynchronous. supports acknowledge too
      - smart broker -> dumb consumer since it manages the offset consumed
      - uses push model from queue to consumer
      - has control over consistency 
      - does not have message ordering 
      - does not guarantee atomicity
      Use case - low latency requests where acknowledgement is needed
        - Applications that need to support legacy protocols, such as STOMP, MQTT, AMQP, 0-9-1.
        - Granular control over consistency/set of guarantees on a per-message basis
        - (Smart broker) - Complex routing to consumers
        - Applications that need a variety of publish/subscribe, point-to-point request/reply messaging capabilities.


    Streaming vs Batching systems 
     https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation
     Batch : MapReduce
     Stream : Flink (also mentioned in https://bytebytego.com/courses/system-design-interview/metrics-monitoring-and-alerting-system )


    Block storage vs File Storage vs Object storage
      https://bytebytego.com/courses/system-design-interview/s3-like-object-storage 
      Block storage
        Common storage devices like hard disk drives (HDD) and solid-state drives (SSD) that are physically attached to servers are all considered as block storage. Files are split into evenly size blocks of data with each block having its own address. Block storage presents the raw blocks to the server as a volume. This is the most flexible and versatile form of storage. The server can format the raw blocks and use them as a file system, or it can hand control of those blocks to an application.
        - can mount VM to this using iSCSI protocol
        - used in operational systems and databases
        - As per geeksforgeeks, this storage is not accessible via the internet and only for attaching to VMs (https://www.geeksforgeeks.org/difference-between-aws-s3-and-aws-ebs/)

      File storage
        - built on top of block storage. It provides a higher-level abstraction to make it easier to handle files and directories. Data is stored as files under a hierarchical directory structure. 
        - File storage could be made accessible by a large number of servers using common file-level network protocols like SMB/CIFS [3] and NFS [4].
        - high performant as block storage
        - used in big data applications, which demand significant node throughput, low-latency file access, and read-after-write operations.

      Object storage 
        - low cost, vast scalability and supports binary+unstructured data as compared to block and file. It is low performant though.
        - Object storage stores all data as objects in a flat structure. There is no hierarchical directory structure. Data access is normally provided via a RESTful API.
        - Data lake and big data analytics, Backup and restoration, Reliable disaster recovery and Methodical archiving using S# Glacier

      AWS EBS vs EFS vs S3 : https://www.missioncloud.com/blog/resource-amazon-ebs-vs-efs-vs-s3-picking-the-best-aws-storage-option-for-your-business
      EBS vs S3 video - https://www.youtube.com/watch?v=r8bVw0iVvGk 
      

  Cache benchmarking

    Azure Redis Cache : 
        53 GB, with 99.9% availability (https://github.com/Huachao/azure-content/blob/master/articles/redis-cache/cache-faq.md)
        230 us (https://redis.io/docs/management/optimization/latency/)
        Redis QPS - 50K https://redis.io/docs/management/optimization/benchmarks/
        1 million TPS - https://bytebytego.com/courses/system-design-interview/digital-wallet 
        Redis also privides sorted set data structure. Our leaderboard use case maps perfectly to sorted sets. Internally, a sorted set is implemented by two data structures: a hash table and a skip list [1]. The hash table maps users to scores and the skip list maps scores to users. In sorted sets, users are sorted by scores. (https://bytebytego.com/courses/system-design-interview/real-time-gaming-leaderboard)
        Sorted set is used in Rate limiter sliding window design which fetches based on timestamp range and avoids race conditions. 
        Redis cluster also supports sharding with hash slot ( different from consistent hashing)
        Redis cluster uses master-replica model
        Redis Cluster does not guarantee strong consistency
        Max Size of each redis instance from AWS : 500 GB https://aws.amazon.com/elasticache/pricing/?nc=sn&loc=4 
        Sorted Set - https://redis.io/docs/data-types/sorted-sets/
        How redis works 
          https://www.youtube.com/watch?v=5TRFpFBccQM

    CDN
        https://www.youtube.com/watch?v=RI9np1LWzqw
        - brings content closer to the user to increase the performance
        - CDN server locations called point of presence PoPs. Server inside POPs are called edge server
        - DNS based routing and anycast used to send the content to the user
        - reduce bandwidth requirements of origin server
        - can minify js files, transform image from old format to modern format
        - Because of its reverse proxy capabilities, all TLS connection terminate at edge server(CDN) thereby reducing TLS handshake overhead. One of the reason why modern servers cache dynamic content on CDN
        - Security : huge network capacity to avoid DDOS attacks. CDN built on anycast network to diffuse ddos traffic
        - Improves availability by having copies available at many locations 

        Pricing 
          https://cloud.google.com/cdn/pricing 
          - remember CDN charges for egress (0.02$ per GiB), cache fill (same charge - 0.01$ per GiB) and 0.0075 per 10K req

          https://bytebytego.com/courses/system-design-interview/design-youtube 
          Let us use Amazon’s CDN CloudFront for cost estimation (Figure 2) [3]. Assume 100% of traffic is served from the United States. The average cost per GB is $0.02. For simplicity, we only calculate the cost of video streaming.

          5 million * 5 videos * 0.3GB * 0.02 = 150,000 per day.

          
      

  SQL DB and benchmarking - Relational
    1. MySQL benchmarking
          - Indexed Read
              a. with primary key reads which is already indexed
                (https://dev.mysql.com/blog-archive/mysql-connection-handling-and-scaling/)
                Recommend 4 * number of cores parallel for ~ 200 us based on simple primary key look ups. For example, 120 (~4 * 32) parellel requests for 32 cores will take 200 us
                1K requests on 32 will take ~ 1ms for simply select query
          
          - Write
            7 K writes/s for 48 core http://minervadb.com/wp-content/uploads/2020/10/MySQL-8-Performance-Benchmarking-on-Amazon-EC2.pdf 
            impact of write performance on indexing
              4 times slower : https://logicalread.com/impact-of-adding-mysql-indexes-mc12/#.Y__7d-zMLuU 
              ~1 K writes/s for 48 core

          - General benchmarking
            Today, a relational database running on a typical data center node can support a few thousand transactions per second.


          - Max size set by MySQL
            256 TB (https://dev.mysql.com/doc/mysql-reslimits-excerpt/8.0/en/table-size-limit.html#:~:text=You%20are%20using%20a%20MyISAM,2567%20%E2%88%92%201%20bytes)
            AWS limit : 64 TB
            According to Amazon Relational Database Service (RDS) [12], you can get a database server with 24 TB of RAM.

          Some facts
          - MySQL client <-> server is socket based connection. Check why ?
          - Max connection limit for MySQL = 100 K
          - per connection -> one user thread
          - size of user thread depends on THD connection data structure which is per connection ~ 10 MB 
          - max THD ~ 10K 
          - So recommended min size of your MySQL = 10 MB * 10 K = 100 GB ??

          - MySQL sorting (https://www.pankajtanwar.in/blog/what-is-the-sorting-algorithm-behind-order-by-query-in-mysql)
              External merge sort (quick sort + merge sort) if data doesn’t fits into the memory
              Quick sort, if data fits into the memory and we want all of it
              Heap sort, if data fits into the memory but we are using LIMIT to fetch only some results
              Index lookup (not exactly a sorting algorithm, just a pre-calculated binary tree)

          - MySQL query cache (https://docs.oracle.com/cd/E17952_01/mysql-5.1-en/query-cache.html)
              As of MySQL 5.1.63, the query cache is not supported for partitioned tables, and is automatically disabled for queries involving partitioned tables. The query cache cannot be enabled for such queries. 

          - MySQL sharding (https://stackoverflow.com/questions/1610887/how-to-partition-mysql-across-multiple-servers)
              this is different from mysql partitioning (https://vertabelo.com/blog/everything-you-need-to-know-about-mysql-partitions/)
          
          - Moreover, MySQL involves no standard implementation for sharding. (https://kinsta.com/blog/mongodb-vs-mysql/)

          - MySQL indexing 
              https://www.youtube.com/watch?v=YuRO9-rOgv4 using B tree
              B tree performance : https://www.youtube.com/watch?v=FgWbADOG44s 
              Its inefficient as compared to B tree for writes : https://www.youtube.com/watch?v=I6jB0nM9SKU 

          - MySQL replica sync
              https://serverfault.com/questions/30605/how-fast-is-mysql-replication
              MySQL replication happens as close to real-time as possible (AWS has <200 ms SLA), as limited by disk and network I/O. The slaves open a socket to the master, which is kept open. When a transaction occurs on the master, it gets recorded in the binlog, and is simply replayed on the slave(s). If the socket between master and slave is interrupted, the binlog is replayed for the slave upon the next successful connection.


          - Multi-region failover time for AWS RDS : 60-100s 
              https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZSingleStandby.html

          - Replication lag for AWS RDS : < 100 ms 
              https://www.bluematador.com/docs/troubleshooting/rds-replica-lag#:~:text=Replication%20lag%20measures%20how%20far,than%20100ms%20of%20replication%20lag. 


          - Practical
              how MySQL gurantees ACID : https://www.youtube.com/watch?v=0OYFsJ1-1YA
              Nice theoretical : https://www.youtube.com/watch?v=clPPKgYJC10 
                Atomicity : begin trans --> comitt statement
                Consistency : integrity constraints (guessing)
                Isolation : concurency control subsytem. done through locks
                Durability : ? 

    2. CockroachDB
      https://github.com/cockroachdb/cockroach/blob/master/docs/design.md 
        CockroachDB is a distributed SQL database. The primary design goals are scalability, strong consistency and survivability (hence the name). CockroachDB aims to tolerate disk, machine, rack, and even datacenter failures with minimal latency disruption and no manual intervention. CockroachDB nodes are symmetric; a design goal is homogeneous deployment (one binary) with minimal configuration and no required external dependencies. 
        Distributed transaction : https://www.youtube.com/watch?v=OJySfiMKXLs&t=1271s 
        Benchmarking : 
        AWS
          https://aws.amazon.com/marketplace/pp/prodview-3zbkzekdohwly  
          4 vCPU, 1500 IOPS
        Benchmark
          https://www.cockroachlabs.com/docs/v22.2/performance.html
              



    NoSQL value DB and benchmarking
        1. Timeseries : OpenTSDB / InfluxDB
              8 cores and 32GB RAM can handle over 250,000 writes per second, greater than 1 M series
              (https://bytebytego.com/courses/system-design-interview/metrics-monitoring-and-alerting-system)

              Performance optimization
                https://bytebytego.com/courses/system-design-interview/metrics-monitoring-and-alerting-system
                  According to a research paper published by Facebook [24], at least 85% of all queries to the operational data store were for data collected in the past 26 hours. If we use a time-series database that harnesses this property, it could have a significant impact on overall system performance. If you are interested in the design of the storage engine, please refer to the design document of the Influx DB storage engine [26].
                  - Storage : Store only delta for timestamps
                  - Storage and querying : Downsampling
                  - use cold storage for old data

        2. Object storage / cold storage benchmarking
            S3 Standard is designed for 99.99% data availability and durability of 99.999999999% of objects across multiple Availability Zones in a given year. AWS S3 provides a great performance. It automatically scales to high request rates, with a very low latency of 100–200 milliseconds.Your application can achieve at least 3,500 PUT/COPY/POST/DELETE and 5,500 GET/HEAD requests per second per prefix in a bucket (https://aws.plainenglish.io/optimize-your-aws-s3-performance-27b057f231a3)
            Another option is to store the data in Amazon S3 using one of the columnar data formats like ORC [5], Parquet [6], or AVRO [7]. We could put a cap on the size of each file (say, 10GB) and the stream processor responsible for writing the raw data could handle the file rotation when the size cap is reached. (https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation)


        3. Cassandra

              100s video : https://www.youtube.com/watch?v=ziq7FUKpCS8
              Slower version of 100s : https://www.youtube.com/watch?v=YjYWsN1vek8 
              
             
              How Cassandra data is  stored in disk :  
                https://www.baeldung.com/cassandra-storage-engine (LSM Tree + SS Table + Spare Index)
               
                
              Cassandra as Columnar databse :
                https://stackoverflow.com/questions/13010225/why-many-refer-to-cassandra-as-a-column-oriented-database
                http://dbmsmusings.blogspot.com/2010/03/distinguishing-two-major-types-of_29.html
                https://www.baeldung.com/cassandra-column-family-data-model 
                  - Its not a direct column based store but its based on column family which stores data row wise
                
                Cassandra column family : 
                  https://www.scylladb.com/glossary/cassandra-column-family/ 
                  Basically you can create multiple column families with different columns and each will have its own LSM tree + SS Table
                  Practical : 
                  Create multiple column families in Cassandra within a key space
                  https://www.dbrnd.com/2016/05/nosql-create-your-first-cassandra-column-family-table/  

              Use of parition key + clustering key storages in Cassandra
                http://distributeddatastore.blogspot.com/2020/03/cassandra-new-sstable-storage-format.html
                -  parition key to assign the nodes and clustering key as sort key within the nodes


              Cassandra data model and store deep dive: (not super helpful)
               https://www.youtube.com/watch?v=X-_vS8q4nu4&list=PLGkHHA2RcrgeV35CBtIlUjiXJzVXLxMbL&index=3
               https://www.youtube.com/watch?v=69dLARZxIVw&list=PLGkHHA2RcrgeV35CBtIlUjiXJzVXLxMbL&index=4 
                How Cassandra read / write data : https://www.youtube.com/watch?v=t276nhhkkI8&t=523s
              
              Cassandra indexing
                Paritioning : https://www.youtube.com/watch?v=Np5RJpCiCzM
                Clustering used as sort key : https://www.youtube.com/watch?v=OCakxrzwuU4 
                  Remember data in cassandra on disk supports SSTable which is sorted string table.
                  So searching could be done in logN times like relational or mongoDB

              Practical 
                    Cassandra indexing (partition + clustering which is sort key) : https://www.youtube.com/watch?v=S9rmf4X7E_E

              Garbage collection
                4.0 uses Z GC instead of G1 GC (java8 to java 16)

              Cassandra and map-reduce
                https://subscription.packtpub.com/book/data/9781787127296/1/ch01lvl1sec5/mapreduce-and-spark
                Unlike MongoDB, Cassandra does not offer built-in MapReduce capabilities. But it can be integrated with Hadoop in order to perform MapReduce operations across Cassandra data sets, or Spark for real-time data analysis. 

              Cassandra performance on writes + reads on indexes 
                - LSM tree + SS tables
                Great video : https://www.youtube.com/watch?v=I6jB0nM9SKU 
                Good read : https://rahulpradeep.medium.com/sstables-and-lsm-trees-5ba6c5529325 
                B Tree vs LSM tree technique - https://www.youtube.com/watch?v=4z7-SrDiBoU

              Consistent hashing
                If we add a new node to the cluster, it automatically rebalances the virtual nodes among all nodes. No manual resharding is required. See Cassandra’s official documentation for more details [22]. - https://bytebytego.com/courses/system-design-interview/ad-click-event-aggregation 
                
              Benchmarking
                - On Cheap heardware https://benchant.com/blog/cassandra-4-performance
                  m5.large ( 2 core, 8 GB) 
                  Read : 7 K ops/s
                  Write : 7 K ops/s
                  Read Latency : ~10 ms
                  Write Latency : ~7 ms

                - Expensive hardware https://www.scylladb.com/2021/08/19/cassandra-4-0-vs-cassandra-3-11-comparing-performance/
                  i3.4xlarge (16 vCPUs, 122 GB)
                   Read : 30 K ops/s
                   Write : 20 K ops/s
                   Read Latency : ~10 ms
                   Write Latency : ~10 ms

        4. MongoDB
              - How Mongo DB search works : https://www.youtube.com/watch?v=tSgPhxZdhLk&t=96s 
                  using index in B tree
              - MongoDB supports range-based or hash-based sharding - https://kinsta.com/blog/mongodb-vs-mysql/
              - For aggregations, Instead of map-reduce, you should use an aggregation pipeline. Aggregation pipelines provide better performance and usability than map-reduce. https://www.mongodb.com/docs/manual/core/map-reduce/
              - How Mongo DB sharding works : https://kinsta.com/blog/mongodb-vs-mysql/ 
              - Practical
                  set up mongo based sharding https://www.youtube.com/watch?v=mjSNKjTzeao 
                  mongoDB gridFS https://www.youtube.com/watch?v=mZE3aBdr010 

        6. Dynamo DB
            Nice intro in https://bytebytego.com/courses/system-design-interview/real-time-gaming-leaderboard

            DynamoDB is a fully managed NoSQL database that offers reliable performance and great scalability. To allow efficient access to data with attributes other than the primary key, we can leverage global secondary indexes [16] in DynamoDB. A global secondary index contains a selection of attributes from the parent table, but they are organized using a different primary key. 
            So Every global secondary index must have a partition key, and can have an optional sort key. The index key schema can be different from the base table schema. 

            DynamoDB splits data across multiple nodes using consistent hashing.


        7. S3

        8. Neo4j

        9. RocksDB
           https://rocksdb.org/
          embeddable persistent key-value store for fast storage
          - high performance due to LSM implementations
          - RocksDB is optimized for fast, low latency storage such as flash drives and high-speed disk drives. RocksDB exploits the full potential of high read/write rates offered by flash or RAM.
          RocksDB                                 vs                    Redis 
          optimized for SSDs(flash), disks                              in-memory db
          more storage larger than RAM                                  storage size restricted due to RAM (in-memory)
          performance close to its SSD/Disk (~1-10ms)                   best performance (200 us with 50K transaction on 53 G)

  Bigdata systems today
    Understand Hadoop ecosystem
      https://www.youtube.com/watch?v=YzAAhbmSt_k
      MapReduce - allows parallel processing and merging
      HDFS - Highly distributed file system based on Google file system (GFS)
      YARN - Job scheduling and resource management
      Common utilitieis
    https://ahana.io/learn/comparisons/hive-vs-presto-vs-spark/ 

    HBase
      It is nothing but a hadoop database and its no SQL. Great layered diagram in https://www.educba.com/hadoop-vs-hbase/ 

    Hive
      https://www.youtube.com/watch?v=taTfW2kXSoE 
      - Hive creates SQL query layer which in turen uses map reduce to query big tables stored in HDFS. This helps SQL experts query big data in HDFS directly in SQL and does not need complicated logic of map reduce.
      - Hive is not a database

      Hive architecture - https://www.youtube.com/watch?v=rr17cbPGWGA&t=270s
        Hive is optimized for query throughput and thus supports large data aggregations 

    Presto
      https://www.youtube.com/watch?v=hEFsHQ_kJR8 
       - similar to Hive, but has amazing capability of query multiple databases - noSQL + SQL ones including Hive. It is optimized for latency and thus used for interactive queries or quick data exploration. Facebook uses Presto.
      Nice clarification about Presto
        https://ahana.io/learn/presto/
        - Presto does not use Map reduce 
        - Presto is not a database


      How twitter uses presto
        https://www.youtube.com/watch?v=WaooVcS75xA

    Spark
      https://www.ibm.com/cloud/blog/hadoop-vs-spark
        Spark is a Hadoop enhancement to MapReduce. The primary difference between Spark and MapReduce is that Spark processes and retains data in memory for subsequent steps, whereas MapReduce processes data on disk. As a result, for smaller workloads, Spark’s data processing speeds are up to 100x faster than MapReduce.

        Furthermore, as opposed to the two-stage execution process in MapReduce, Spark creates a Directed Acyclic Graph (DAG) to schedule tasks and the orchestration of nodes across the Hadoop cluster. This task-tracking process enables fault tolerance, which reapplies recorded operations to data from a previous state.

        Working of DAG Optimizer in Spark
        https://data-flair.training/blogs/dag-in-apache-spark/
          We optimize the DAG in Apache Spark by rearranging and combining operators wherever possible. For, example if we submit a spark job which has a map() operation followed by a filter operation. The DAG Optimizer will rearrange the order of these operators since filtering will reduce the number of records to undergo map operation.

        Then why DAG is better than MapReduce ? 
          BEST - explanation  
          https://www.quora.com/What-are-the-advantages-of-DAG-directed-acyclic-graph-execution-of-big-data-algorithms-over-MapReduce-I-know-that-Apache-Spark-Storm-and-Tez-use-the-DAG-execution-model-over-MapReduce-Why-Are-there-any-disadvantages 

          DAG resource manager example - Apache Airflow
            https://www.youtube.com/watch?v=mtJHMdoi_Gg 

        

  Attempt to standardized DB selection criteria 
      1. MySQL vs noSQL 

            When MySQL
            if ACID, 
              then MYSQL (high confidence)
            if reasonable size (< 1 TB) not expected to scale rapidly,
              if heavy reads (reading from read replicas is faster) 
                if low writes 
                  then MySQL (high confidence)
                if heavy writes (else have to keep synchronizing and index making)
                  then MySQL (low confidence)
            If db needs rapid scale (size keeps growing)
              if manual sharding is needed ( say by user id )
                if sharding has all related rows (try to denormalize)
                  if there are less aggregations 
                    then MySQL (medium confidence)
                  if there are more aggregations 
                    then MySQL (low confidence since aggregations with sharding could be better achieved with noSQL DBs like MongoDB, Cassandra)
            If db needs better search performance (not full text search)  
              if index-ing on fixed columns,
                then MySQL (high confidence)
              if db experience heavy writes
                then MySQL (low confidence since indexes increases write latency) 

      2.  MySQL vs MongoDB

      3.  MongoDB vs Cassandra
            https://www.youtube.com/watch?v=3z2EzILA3Rk 

                Cassandra                          vs               MongoDB 
            column data model                                   json document data model
            no config server(ring structure)                    mongo master, slave and mongo config servers for replication
            high availability due to multiple masters           master -> slave takes time
            accept writes in parallel                           write capacity is limited since they just go to master
            similar to SQL                                        based on json formatting

            When mongo DB
              query also based on secondary indexing and flexible querying
              built in data aggregation framework
              read-heavy workload

            When Cassandra 
                query based on primary key indexing 
                100% uptime guarantee due to replication and inconsistency resolution
                high write speed
                language support for SQL
                write-heavy, read-heavy workload
                eventual consistency (as per bytebytego - https://bytebytego.com/courses/system-design-interview/design-a-key-value-store )

     

      Open questions
            1. Why is MySQL better for read heavy low write workload ? answered above
            2. MySQL is better for ACID systems and structured ? How ? answered above
            2. How MySQL syncs with its replicas ? answered above
            2. Why is Cassandra (noSQL) better for read heavy write heavy workload ? answered above
            3. Aggregation on sharded MySQL needs Application level handling vs Cassandra or HBase(Column) can handle this since they are built on top of distributed systems . Fact and derived above
            4. How MySQL indexing works ? answered above
            5. Cassandra benchmarking ? answered above
            7. Time taken from master to slave - MySQL, MongoDB ? MySQL ( 200 ms aws)
            9. Refer NTP ? answered above
            8. MongoDB benchmarking ?
            6. Study about graphdbs ? 

 Operation system
    User level threads vs Kernel level threads
      https://www.youtube.com/watch?v=_5q8ZK6hwzM

 
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================
=========================================================================================================================


References

Dump : https://coursehunters.online/t/educative-io-design-gurus-grokking-the-system-design-interview-part-5/584
Quick read : https://github.com/Jeevan-kumar-Raj/Grokking-System-Design

    
- Load balancing
    Resources
      https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/load-balancing.md
      https://www.cloudflare.com/learning/performance/types-of-load-balancing-algorithms/
      https://igotanoffer.com/blogs/tech/load-balancing-system-design-interview
    Static load balancing - round robin, weight round robin, IP hash
    Dynamic load balanacing - least connection, least resource, least response time, least bandwidth
    When to use Static ?
      If the server pool and the requests are both homogeneous, and there is only one balancer. Stateless servers handling single api can use static load balancer
      
    When to use Dynamic ?
      if the requests are heterogenous, Least Load is helpful to prevent servers from being intermittently overloaded.
      
    What are Hardware load balancers ?
      They have high performant hardware resources like L4 and L7. 
      Read about L4 and L7 here https://levelup.gitconnected.com/l4-vs-l7-load-balancing-d2012e271f56
      
    What are Software load balancers ?
      They run on standard servers and are less hardware optimized, but cheaper to set up and run. Example, Nginx or HAProxy. For Nginx 100s video, 
      refer https://www.youtube.com/watch?v=JKxlsvZXG7c. Nginx can serve routing to different servers, rate limiting, handle spikes,
      reverse proxy, security, cache, etc. 
      
    When to use Software or Hardware ?
      Tip : Since software load balancing can run on ordinary hardware and supports, always prefer software load balancer. Example Nginx
       
      
    What is proxy server, reverse proxy and API Gateway ? How is different from load balancer
      proxy vs reverse proxy vs load balancer : https://www.youtube.com/watch?v=MiqrArNSxSM
      Proxy : just protects the client side
      Reverse Proxy : protects the server by serving as proxy for all backend services - routing, rate limitng, load balancing
      API gateway : rate limiting, routing, handle spikes
      Load balancer : only performs load balancing
      
      So Reverse proxy can perform both API Gateway and Load Balancing. Example nginx.
      A load balancer can never be API gateway or reverse proxy.
      
     Always choose Nginx ? Why ?
       Has triats of load balancing + reverse proxy + API gateway
         - supports load balancing
         - supports request forwarding based on different paths like api gateway
         - supports reverse proxy 
         - supports rate limiting
         - supports caching
         - supports request grouping
         - supports secure auth SSL. Also does optimizations with keep alive connection and cache to avoid SSL handshake - https://docs.nginx.com/nginx/admin-guide/security-controls/terminating-ssl-http/ 
         Also a good read https://www.nginx.com/blog/http-keepalives-and-web-performance/
       Nginx supports L7
================================================================

      
  - Caching
    Resources
      https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/caching.md
      Distributed cache on Application server VS Global cache like Redis, (mostly preferred)
      CDN is another form of cache for static content but its often expensive
      
          
       What are different caching strategies ? 
          https://codeahoy.com/2017/08/11/caching-strategies-and-how-to-choose-the-right-one/
          Cache-Aside (application server has cache aside like Redis, Memcache and DB separately)
            - Pros : logic controlled by application server, resilent to cache failures, data model in cache vs db could be different
            - Cons : stale data in cache for db writes
          Read-Through Cache (application server reads from cache only)
            - Pros : logic controlled by cache, read-heavy, good consistency when combined with write through 
            - Cons : needs data model to be consistent, first time data always results in cache miss
            Application : autocomplete suggestion to read from trie cache - https://bytebytego.com/courses/system-design-interview/design-a-search-autocomplete-system 

          Belpw are Cache writes invalidation policy 

          d through (data is written to cache and synced with storage)
            - Pros : fast retreival and data consistent systems
            - Cons : slow writes though
          Write around (data is written to storage, not cache)
            - Pros : Saves write operation on the cache
            - Cons : recently written data creates a cache miss and higher latency.
          Write back (data is written to cache only, then synced later to storage)
            - Pros : fast retreival, low latency read / writes
            - Cons : Risk of data loss
            
        Real applications of 
          1. read-through, write-through for high consistency
                DynamoDB Accelerator (DAX) for dynamoDB
          2. read-through, write-around for high performance for situations where data is written once and read less frequently or never.
                real-time logs, chatroom messages
          3. cache-aside, write back cache to absorb spikes during peak load
                custom applications using redis
          4. write back cache
                InnoDB which is relational database storage engine. Queries are first written to memory and eventually flushed to the disk.
                
                
================================================================
    - Sharding / Partitioning 
        Resources
          https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/sharding.md
          https://coursehunters.online/t/educative-io-design-gurus-grokking-the-system-design-interview-part-5/584
          Horizontal, Vertical and Directory based paritioning
            Directory based paritioning has work around to solve some challenges with Horizontal and Vertical?
          What's the best Partitioning criteria ?
            Consitent hashing which is combination of hash and list based partitioning
          Commom problems with Sharding / Partitioning
            Joins -> Denormalization
            Referential Integrity (primary key -> foreign key. look at image in https://en.wikipedia.org/wiki/Referential_integrity)
            Hot shard problem needs rebalancing
              How to rebalance ? 
              It would take downtime, check directory based partitioning as per our educative.io resource.
              But consistent hashing can solve this problem better - https://medium.com/nerd-for-tech/consistent-hashing-6524e48ac648
              Great guide above - check consistent hashing with gossip protocol so that each partition knows where to fetch data from db
          Applications of consistent hashing ?
          Apache Cassandra, Dynamo DB
 
 ================================================================

    - Indexing
        Resources
          https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/indexes.md
          What is a database index ? 
            https://www.codecademy.com/article/sql-indexes
          Pros
            helps in speeding up the search 
          Cons
            lowers write/update/delete performance by 4 times
          When to use indexes ?
            In the case of data sets that are many terabytes in size but with very small payloads (e.g., 1 KB), 
            indexes are a necessity for optimizing data access. Finding a small payload in such a large dataset can be a real challenge since
            we can’t possibly iterate over that much data in any reasonable time. Furthermore, it is very likely that such a large data set is 
            spread over several physical devices—this means we need some way to find the correct physical location of the desired data. 
            Indexes are the best way to do this.
            
   ================================================================

     - Proxy 
        Resources
          https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/proxies.md
          
          Usage : 
          filter requests, log requests, cache, encryption and most important batch request. Further, it can get smarter to o collapse requests for data that is spatially close together in the storage (consecutively on disk). This strategy will result in decreasing request latency. 
          For example, let’s say a bunch of servers request parts of file: part1, part2, part3, etc. We can set up our proxy in such a way 
          that it can recognize the spatial locality of the individual requests, thus collapsing them into a single request and reading complete file, 
          which will greatly minimize the reads from the data origin.
          
          Proxy are of two types 
          Client proxy to protect the clients
          Server proxy to protect the servers. Also called reverse proxy
          
          Should we use proxy then?
          Only use proxy to protect the client.
          For server side, Always Nginx since its open source and supports both reverse proxy + load balancing + API gateway.
          
          
   
   ==============================================================================

          Queues
          
            Resource :
            - https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/queues.md
            
            When to use queue :
            Queues are implemented on the asynchronous communication protocol, meaning when a client submits a task to a queue they 
            are no longer required to wait for the results; instead, they need only acknowledgment that the request was properly received.
            
            Queues are also used for fault tolerance as they can provide some protection from service outages and failures. For example, 
            we can create a highly robust queue that can retry service requests that have failed due to transient system failures
            
            When not to use queue :
            When client expects respone in real-time
            
            Example of queues : 
             RabbitMQ and Kafka (which is open source)
             
  ====================================================================================
  
        Redundancy and Replication
        
          Resource : 
          https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/redundancy.md
          
          When to use Redundant system :
          Always. its a key concept of distributed system.
          Always prefer shared nothing architecture so that each node can operate independently and can scale.
          
          
    ====================================================================================
        SQL vs NoSQL
        
          Resource : 
          https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/sql-vs-nosql.md
          
          SQL 
          Relational databases store data in rows and columns. Example, MySQL, Oracle, MS SQL Server, SQLite, Postgres
          
          NoSQL 
          Key-value :  Example, DynamoDB, Redis, Memcache
          Document DB : Example, MongoDB, 
          Wide-Column Database : Example, HBase, Cassandra - https://hevodata.com/learn/columnar-databases/
          Graph Databases : Example, Neo4j
          
          Differences between both 
          Storage : SQL is tables but NoSQL has different storage models
          Schema : changing schema with SQL is possible but requires whole database modification
          Querying : using SQL for SQL dbs. 
          Scalability : SQL is vertically scalable and possible to scale it horizontally but has limitations. NoSQL is horizontally scalable
          Reliability or ACID : Definitely SQL ensures ACID but NoSQL solutions sacrifice ACID compliance for performance and scalability.
          
          When to use SQL
            ACID compliance for e-commerce and finanicial transactions
            Your data is structured and unchanging.
            Often Read heavy and low-write

            
          When to use NoSQL
            - Storing large volumes of data that often have little to no structure. 
            - Making the most of cloud computing and storage. Cloud-based storage is an excellent cost-saving solution 
            but requires data to be easily spread across multiple servers to scale up. 
            - Rapid development. NoSQL is extremely useful for rapid development as it doesn’t need to be prepped ahead of time. 
            
          What about write performance ? 
          noSQL has better write performance due to SSTable + LSM tree implementation. Example, Cassandra
          

            
            
  ====================================================================================
  
    CAP Theorem
    Resource : 
    https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/cap-theorem.md
    
    CAP theorem states that it is impossible for a distributed software system to simultaneously provide more than two out of three of 
    the following guarantees (CAP): Consistency, Availability and Partition tolerance.
    
    We can only build a system that has any two of these three properties. Because, to be consistent, all nodes should see the same set of updates 
    in the same order. But if the network suffers a partition, updates in one partition might not make it to the other partitions before a client 
    reads from the out-of-date partition after having read from the up-to-date one. The only thing that can be done to cope with this possibility is to stop serving requests from the out-of-date partition, but then the service is no longer 100% available.

    When to choose consistency over availability ? 
      Banking, Payment systems
    
    When to choose availability over consistency   ? 
      Most distributed system use cases like Google Maps, Twitter, etc.
      
    Since reliability consists of both consistency and availability, ASK YOUR interviewer what it means for system to be 99.99% reliable
    
    
   ====================================================================================
 
    Consistent Hashing
    
    Resource 
      https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/consistent-hashing.md
      Recommended ones 
        https://medium.com/nerd-for-tech/consistent-hashing-6524e48ac648 - Explains well about rebalancing
        https://bytebytego.com/courses/system-design-interview/design-consistent-hashing
        
      How does it work ? 
        Hashing is done in the range where it maps the key to the integer in that range. Example 0 -> 255 are the integers placed in ring form such that values are wrapped around.
        
        1. the servers are mapped to the integers in that range
        2. to map key to a server, simply hash the key to the integer in that range and move clockwise till you find the server (could be binary search)
        
        Now how this is better :
        1. adding a server : say S1 is added at position 20 and is near S2 at position 25. Then keys from before 20 wuld map to S1.
        2. removing a server : say S1 is removed at position 20 and was near S2 at position 25. Then  all keys even before 20 would map to S2. 
        3. uniform distribution : add “virtual replicas”. Instead of mapping each server to a single point on the ring, 
            we map it to multiple points on the ring, i.e. replicas. 
        4. easy to rebalance : when server is added or removed, only its next clockwise neighbouring server is affected and requires re-mapping of keys.
        
        
    ====================================================================================
    
    Client-Server Communication
    
      Resource : 
        https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/client-server-communication.md
        
      Types : 
      1. Standard HTTP Web Request : client opens the connection, gets response from the server and terminate the connection 
      2. Ajax Polling : client performs HTTP Web Request above periodically (say every 1 s). May create unecessary empty responses if server is not ready.
      3. Long Polling : client performs HTTP Web Request and waits for long time till response is received (say 1 min). Then sends request again.
      4. Web Socket: persistent connection between a client and a server that both parties can use to start sending data at any time.
      5. SSE :  persistent onnection between a client and a server where server send data to the client but not the reverse
      
      When to use Long Polling vs Web Socket ? 
        https://ably.com/blog/websockets-vs-long-polling
        https://dev.to/kevburnsjr/websockets-vs-long-polling-3a0o
        
        Clearly Websockets have many advantages over long polling and thus are appropriate for many applications which require consistent low latency 
        full duplex high frequency communication such as chat applications and real time applications.
        
        Scaling up 
        Websockets have problems with load distribution due to persistent connection.
        Long polling will have equal load distribution after its long timeout
        
     When to use Web Socker vs Server Sent Events ?
        Websocket for bi-directional communication while SSE for server to client communication
        https://blog.bitsrc.io/websockets-vs-server-sent-events-968659ab0870
        
        WebSockets are widely used and valued in technological solutions such as real-time polling, chat, media players, multiplayer games, etc.
        Server-Sent Events: There are many applications where sending data from the client isn’t necessary. 
        SSEs are especially useful in status updates, social-media news feeds, push notifications, newsletters, etc.

      Keep alive : 
        https://www.imperva.com/learn/performance/http-keep-alive/
        - improves latency to avoid 3-way handskae and SSL/TLS connections
        - less consumption of network resources to use single connection. This can drop network conjestion




===============================================================

- Key characteristics
    Resources
      https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/key-characteristics.md 
    Scalability, Availability, Reliability, Efficiency and Servicability/Manageability
    -> Remember an Avaiability system does not means Reliable but Reliable system is always available. 

  How to handle burst / spiky reads ? 
    Use Nignx to do request collapsing for similar type of content
    Use queue if content does not need to be delivered real-time
    Other strategies : Data Cache, CDN (https://www.onecloudsystems.com/2016/10/25/how-to-ensure-site-can-handle-traffic-spikes/)

  Pull vs push models
    In Pull approach, the metrics collector needs to know the complete list of service endpoints to pull data from. The good news is that we have a reliable, scalable, and maintainable solution available through Service Discovery, provided by etcd [14], Zookeeper [15], etc., wherein services register their availability and the metrics collector can be notified by the Service Discovery component whenever the list of service endpoints changes. 
    If a server goes down, then you can re-try in the next pull. But here you need dedupe logic or  store the offset in S3 to know what messages to retry.

    In a push model, a collection agent is commonly installed on every server being monitored. Aggregation is an effective way to reduce the volume of data sent to the metrics collector. If the push traffic is high and the metrics collector rejects the push with an error, the agent could keep a small buffer of data locally (possibly by storing them locally on disk), and resend them later.
    If a server goes down or cannot handle burst traffic, then you loose the message.

  Tips to ensure consistency 
    - To maintain data consistency between internal services, ensuring exactly-once processing is very important.
    - To maintain data consistency between the internal service and external service (PSP), we usually rely on idempotency and reconciliation.
    - For replicas, ensure acknowledge only if all replicas respond to read/write update. 

    
   
================================================================================================================================
- Key learnings from system design

 
  
   
         
    

      
    
   
  

  

  
  
  

  
  

  


  




























              






=================================================================================

    
