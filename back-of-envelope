Links :

https://bytebytego.com/courses/system-design-interview/back-of-the-envelope-estimation

https://matthewdbill.medium.com/back-of-envelope-calculations-cheat-sheet-d6758d276b05

Tips :
- Ask functional requirements first (example, ability to post tweet, view tweet)
- Ask DAU. If MAU is provided, atleast ask % of daily users. 
- Ask user activity : example read vs write ratio, or number of writes (example, 2 tweets per day)
- Ask non-functional requirements 
  These are very important and can convert entire inteview in your favor. Example if latency is 1s, then you do not need complex caching architecture.
    -- Latency 
           this would help decide whether you really need low latency optimizations like cache, or not. 
           Remember today mosts have 1 Gbps network which has 10 us to transfer 1 KB
    -- Availability 
          this would help decide the redundancy and reliability - example mostly 99.99% a day means you can compromise 10s (10 ^ 5 * 10 ^ -4)
          of unavailability or being unrelible. With this you can even decide that, your system could be out of sync from third part servers for 10s in a
          day

QPS estimate
- 1 day ~ 10^5 s
- 1 month ~ 3 * 10 ^ 6s and further ~ 10 ^ 6s
- 1 week ~ 7 * 10 ^ 5s and further ~ 10 ^ 6s
----- For time constraints, do not hesitate to round off large amounts

Distributed Systems estimate

Estimates in KB

Send 1 KB sequential from 1 Gbps network = 10 us  
Send 1 KB sequential from memory  = 0.25 us   (4 GB/s = 0.25 *  10 ^ -6 s) 
Send 1 KB sequential from disk    = 30 us     (30 MB/s = 0.03 * 10 ^ -3 s ) 
Send 1 KB sequential from cache   = 1 us    (1 GB/s = 1 * 10 ^ -6 s ) 

So network is 3 times faster than disk
memory is 40 times faster than network

Benchmarks on common systems

Cache
Azure Redis Cache : 
  53 GB, with 99.9% availability (https://github.com/Huachao/azure-content/blob/master/articles/redis-cache/cache-faq.md)
  230 us (https://redis.io/docs/management/optimization/latency/)




================================================================
References
- Key characteristics
    Resources
      https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/key-characteristics.md 
    Scalability, Availability, Reliability, Efficiency and Servicability/Manageability
    -> Remember an Avaiability system does not means Reliable but Reliable system is always available. 
    
- Load balancing
    Resources
      https://github.com/Jeevan-kumar-Raj/Grokking-System-Design/blob/master/basics/load-balancing.md
      https://www.cloudflare.com/learning/performance/types-of-load-balancing-algorithms/
      https://igotanoffer.com/blogs/tech/load-balancing-system-design-interview
    Static load balancing - round robin, weight round robin, IP hash
    Dynamic load balanacing - least connection, least resource, least response time, least bandwidht
    When to use Static ?
      If the server pool and the requests are both homogeneous, and there is only one balancer
    When to use Dynamic ?
      if the requests are heterogenous, Least Load is helpful to prevent servers from being intermittently overloaded.
      
    What are Hardware load balancers ?
      They have high performant hardware resources like L4 and L7. 
      Read about L4 and L7 here https://levelup.gitconnected.com/l4-vs-l7-load-balancing-d2012e271f56
      
    What are Software load balancers ?
      They run on standard servers and are less hardware optimized, but cheaper to set up and run. Example, Nginx or HAProxy. For Nginx 100s video, 
      refer https://www.youtube.com/watch?v=JKxlsvZXG7c. Nginx can serve routing to different servers, rate limiting, handle spikes,
      reverse proxy, security, cache, etc. 
      
    When to use Software or Hardware ?
      Tip : Since software load balancing can run on ordinary hardware and supports, always prefer software load balancer. Example Nginx
       
      
    What is proxy server, reverse proxy and API Gateway ? How is different from load balancer
      proxy vs reverse proxy vs load balancer : https://www.youtube.com/watch?v=MiqrArNSxSM
      Proxy : just protects the client side
      Reverse Proxy : protects the server by serving as proxy for all backend services - routing, rate limitng, load balancing
      API gateway : rate limiting, routing, handle spikes
      Load balancer : only performs load balancing
      
      So Reverse proxy can perform both API Gateway and Load Balancing. Example nginx.
      A load balancer can never be API gateway or reverse proxy.
      
     Always choose Nginx ? Why ?
       Has triats of load balancing + reverse proxy + API gateway
         - supports load balancing
         - supports reverse proxy 
         - supports rate limiting
         - supports caching
         - supports secure auth
       Nginx supports L7
      
      
      
      
      



